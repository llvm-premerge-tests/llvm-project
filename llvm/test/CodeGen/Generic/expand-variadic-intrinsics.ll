; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -expand-va-intrinsics -expand-va-intrinsics-all=true -S < %s | FileCheck %s

target datalayout = "e-m:e-S8"

; CHECK: %variadic_to_call_middle.vararg = type { i32, [4 x i8], double, i32 }

define dso_local void @variadic_to_call_middle(double %d, ...) {
; CHECK-LABEL: @variadic_to_call_middle(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[VA:%.*]] = alloca ptr, align 8
; CHECK-NEXT:    call void @llvm.lifetime.start.p0(i64 8, ptr nonnull [[VA]])
; CHECK-NEXT:    store ptr [[VARARGS:%.*]], ptr [[VA]], align 8
; CHECK-NEXT:    [[ARGLIST_CURRENT:%.*]] = load ptr, ptr [[VA]], align 8
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds i8, ptr [[ARGLIST_CURRENT]], i32 3
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[TMP0]] to i64
; CHECK-NEXT:    [[TMP2:%.*]] = and i64 [[TMP1]], -4
; CHECK-NEXT:    [[TMP3:%.*]] = inttoptr i64 [[TMP2]] to ptr
; CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr [[TMP3]], align 4
; CHECK-NEXT:    [[ARGLIST_NEXT:%.*]] = getelementptr inbounds i32, ptr [[TMP3]], i64 1
; CHECK-NEXT:    store ptr [[ARGLIST_NEXT]], ptr [[VA]], align 8
; CHECK-NEXT:    [[ARGLIST_CURRENT1:%.*]] = load ptr, ptr [[VA]], align 8
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds i8, ptr [[ARGLIST_CURRENT1]], i32 7
; CHECK-NEXT:    [[TMP6:%.*]] = ptrtoint ptr [[TMP5]] to i64
; CHECK-NEXT:    [[TMP7:%.*]] = and i64 [[TMP6]], -8
; CHECK-NEXT:    [[TMP8:%.*]] = inttoptr i64 [[TMP7]] to ptr
; CHECK-NEXT:    [[TMP9:%.*]] = load double, ptr [[TMP8]], align 8
; CHECK-NEXT:    [[ARGLIST_NEXT2:%.*]] = getelementptr inbounds double, ptr [[TMP8]], i64 1
; CHECK-NEXT:    store ptr [[ARGLIST_NEXT2]], ptr [[VA]], align 8
; CHECK-NEXT:    [[ARGLIST_CURRENT3:%.*]] = load ptr, ptr [[VA]], align 8
; CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds i8, ptr [[ARGLIST_CURRENT3]], i32 3
; CHECK-NEXT:    [[TMP11:%.*]] = ptrtoint ptr [[TMP10]] to i64
; CHECK-NEXT:    [[TMP12:%.*]] = and i64 [[TMP11]], -4
; CHECK-NEXT:    [[TMP13:%.*]] = inttoptr i64 [[TMP12]] to ptr
; CHECK-NEXT:    [[TMP14:%.*]] = load i32, ptr [[TMP13]], align 4
; CHECK-NEXT:    [[ARGLIST_NEXT4:%.*]] = getelementptr inbounds i32, ptr [[TMP13]], i64 1
; CHECK-NEXT:    store ptr [[ARGLIST_NEXT4]], ptr [[VA]], align 8
; CHECK-NEXT:    call void @_Z3erri(i32 [[TMP4]])
; CHECK-NEXT:    call void @_Z3errd(double [[TMP9]])
; CHECK-NEXT:    call void @_Z3erri(i32 [[TMP14]])
; CHECK-NEXT:    call void @llvm.lifetime.end.p0(i64 8, ptr nonnull [[VA]])
; CHECK-NEXT:    ret void
;
entry:
  %va = alloca ptr, align 8
  call void @llvm.lifetime.start.p0(i64 8, ptr nonnull %va)
  call void @llvm.va_start(ptr nonnull %va)
  %0 = va_arg ptr %va, i32
  %1 = va_arg ptr %va, double
  %2 = va_arg ptr %va, i32
  call void @llvm.va_end(ptr %va)
  call void @_Z3erri(i32 %0)
  call void @_Z3errd(double %1)
  call void @_Z3erri(i32 %2)
  call void @llvm.lifetime.end.p0(i64 8, ptr nonnull %va)
  ret void
}

define dso_local void @variadic_to_call_entry(i32 %x0, double %x1, i32 %x2) {
; CHECK-LABEL: @variadic_to_call_entry(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[VARARG_BUFFER:%.*]] = alloca [[VARIADIC_TO_CALL_MIDDLE_VARARG:%.*]], align 8
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[VARIADIC_TO_CALL_MIDDLE_VARARG]], ptr [[VARARG_BUFFER]], i32 0, i32 0
; CHECK-NEXT:    store i32 [[X0:%.*]], ptr [[TMP0]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [[VARIADIC_TO_CALL_MIDDLE_VARARG]], ptr [[VARARG_BUFFER]], i32 0, i32 2
; CHECK-NEXT:    store double [[X1:%.*]], ptr [[TMP1]], align 8
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [[VARIADIC_TO_CALL_MIDDLE_VARARG]], ptr [[VARARG_BUFFER]], i32 0, i32 3
; CHECK-NEXT:    store i32 [[X2:%.*]], ptr [[TMP2]], align 4
; CHECK-NEXT:    tail call void @variadic_to_call_middle(double 1.000000e+00, ptr [[VARARG_BUFFER]])
; CHECK-NEXT:    ret void
;
entry:
  tail call void (double, ...) @variadic_to_call_middle(double 1.0, i32 %x0, double %x1, i32 %x2)
  ret void
}


declare void @llvm.va_start(ptr)
declare void @llvm.va_end(ptr)

declare void @llvm.lifetime.start.p0(i64 immarg, ptr nocapture)
declare void @llvm.lifetime.end.p0(i64 immarg, ptr nocapture)

declare void @_Z3erri(i32)
declare void @_Z3errd(double)
