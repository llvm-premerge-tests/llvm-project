; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --extra_scrub --version 2
; RUN: llc < %s | FileCheck %s
target datalayout = "e-m:e-i8:8:32-i16:16:32-i64:64-i128:128-n32:64-S128"
target triple = "aarch64-unknown-linux-gnu"

define void @rotl_v8i8(<8 x i8> %0, ptr %1) {
; CHECK-LABEL: rotl_v8i8:
; CHECK:       // %bb.0:
; CHECK-NEXT:    shl v1.8b, v0.8b, #2
; CHECK-NEXT:    sri v1.8b, v0.8b, #6
; CHECK-NEXT:    str d1, [x0]
; CHECK-NEXT:    ret
  %3 = tail call <8 x i8> @llvm.fshl.v8i8(<8 x i8> %0, <8 x i8> %0, <8 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>)
  store <8 x i8> %3, ptr %1, align 8
  ret void
}

define void @rotr_v8i8(<8 x i8> %0, ptr %1) {
; CHECK-LABEL: rotr_v8i8:
; CHECK:       // %bb.0:
; CHECK-NEXT:    shl v1.8b, v0.8b, #6
; CHECK-NEXT:    sri v1.8b, v0.8b, #2
; CHECK-NEXT:    str d1, [x0]
; CHECK-NEXT:    ret
  %3 = tail call <8 x i8> @llvm.fshl.v8i8(<8 x i8> %0, <8 x i8> %0, <8 x i8> <i8 -2, i8 -2, i8 -2, i8 -2, i8 -2, i8 -2, i8 -2, i8 -2>)
  store <8 x i8> %3, ptr %1, align 8
  ret void
}

define void @rotl_v16i8(<16 x i8> %0, ptr %1) {
; CHECK-LABEL: rotl_v16i8:
; CHECK:       // %bb.0:
; CHECK-NEXT:    shl v1.16b, v0.16b, #2
; CHECK-NEXT:    sri v1.16b, v0.16b, #6
; CHECK-NEXT:    str q1, [x0]
; CHECK-NEXT:    ret
  %3 = tail call <16 x i8> @llvm.fshl.v16i8(<16 x i8> %0, <16 x i8> %0, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>)
  store <16 x i8> %3, ptr %1, align 16
  ret void
}

define void @rotr_v16i8(<16 x i8> %0, ptr %1) {
; CHECK-LABEL: rotr_v16i8:
; CHECK:       // %bb.0:
; CHECK-NEXT:    shl v1.16b, v0.16b, #6
; CHECK-NEXT:    sri v1.16b, v0.16b, #2
; CHECK-NEXT:    str q1, [x0]
; CHECK-NEXT:    ret
  %3 = tail call <16 x i8> @llvm.fshl.v16i8(<16 x i8> %0, <16 x i8> %0, <16 x i8> <i8 -2, i8 -2, i8 -2, i8 -2, i8 -2, i8 -2, i8 -2, i8 -2, i8 -2, i8 -2, i8 -2, i8 -2, i8 -2, i8 -2, i8 -2, i8 -2>)
  store <16 x i8> %3, ptr %1, align 16
  ret void
}

define void @rotl_v4i16(<4 x i16> %0, ptr %1) {
; CHECK-LABEL: rotl_v4i16:
; CHECK:       // %bb.0:
; CHECK-NEXT:    shl v1.4h, v0.4h, #2
; CHECK-NEXT:    sri v1.4h, v0.4h, #14
; CHECK-NEXT:    str d1, [x0]
; CHECK-NEXT:    ret
  %3 = tail call <4 x i16> @llvm.fshl.v4i16(<4 x i16> %0, <4 x i16> %0, <4 x i16> <i16 2, i16 2, i16 2, i16 2>)
  store <4 x i16> %3, ptr %1, align 8
  ret void
}

define void @rotr_v4i16(<4 x i16> %0, ptr %1) {
; CHECK-LABEL: rotr_v4i16:
; CHECK:       // %bb.0:
; CHECK-NEXT:    shl v1.4h, v0.4h, #14
; CHECK-NEXT:    sri v1.4h, v0.4h, #2
; CHECK-NEXT:    str d1, [x0]
; CHECK-NEXT:    ret
  %3 = tail call <4 x i16> @llvm.fshl.v4i16(<4 x i16> %0, <4 x i16> %0, <4 x i16> <i16 -2, i16 -2, i16 -2, i16 -2>)
  store <4 x i16> %3, ptr %1, align 8
  ret void
}

define void @rotl_v8i16(<8 x i16> %0, ptr %1) {
; CHECK-LABEL: rotl_v8i16:
; CHECK:       // %bb.0:
; CHECK-NEXT:    shl v1.8h, v0.8h, #2
; CHECK-NEXT:    sri v1.8h, v0.8h, #14
; CHECK-NEXT:    str q1, [x0]
; CHECK-NEXT:    ret
  %3 = tail call <8 x i16> @llvm.fshl.v8i16(<8 x i16> %0, <8 x i16> %0, <8 x i16> <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>)
  store <8 x i16> %3, ptr %1, align 16
  ret void
}

define void @rotr_v8i16(<8 x i16> %0, ptr %1) {
; CHECK-LABEL: rotr_v8i16:
; CHECK:       // %bb.0:
; CHECK-NEXT:    shl v1.8h, v0.8h, #14
; CHECK-NEXT:    sri v1.8h, v0.8h, #2
; CHECK-NEXT:    str q1, [x0]
; CHECK-NEXT:    ret
  %3 = tail call <8 x i16> @llvm.fshl.v8i16(<8 x i16> %0, <8 x i16> %0, <8 x i16> <i16 -2, i16 -2, i16 -2, i16 -2, i16 -2, i16 -2, i16 -2, i16 -2>)
  store <8 x i16> %3, ptr %1, align 16
  ret void
}

define void @rotl_v2i32(<2 x i32> %0, ptr %1) {
; CHECK-LABEL: rotl_v2i32:
; CHECK:       // %bb.0:
; CHECK-NEXT:    shl v1.2s, v0.2s, #2
; CHECK-NEXT:    sri v1.2s, v0.2s, #30
; CHECK-NEXT:    str d1, [x0]
; CHECK-NEXT:    ret
  %3 = tail call <2 x i32> @llvm.fshl.v2i32(<2 x i32> %0, <2 x i32> %0, <2 x i32> <i32 2, i32 2>)
  store <2 x i32> %3, ptr %1, align 16
  ret void
}

define void @rotr_v2i32(<2 x i32> %0, ptr %1) {
; CHECK-LABEL: rotr_v2i32:
; CHECK:       // %bb.0:
; CHECK-NEXT:    shl v1.2s, v0.2s, #30
; CHECK-NEXT:    sri v1.2s, v0.2s, #2
; CHECK-NEXT:    str d1, [x0]
; CHECK-NEXT:    ret
  %3 = tail call <2 x i32> @llvm.fshl.v2i32(<2 x i32> %0, <2 x i32> %0, <2 x i32> <i32 -2, i32 -2>)
  store <2 x i32> %3, ptr %1, align 16
  ret void
}

define void @rotl_v4i32(<4 x i32> %0, ptr %1) {
; CHECK-LABEL: rotl_v4i32:
; CHECK:       // %bb.0:
; CHECK-NEXT:    shl v1.4s, v0.4s, #2
; CHECK-NEXT:    sri v1.4s, v0.4s, #30
; CHECK-NEXT:    str q1, [x0]
; CHECK-NEXT:    ret
  %3 = tail call <4 x i32> @llvm.fshl.v4i32(<4 x i32> %0, <4 x i32> %0, <4 x i32> <i32 2, i32 2, i32 2, i32 2>)
  store <4 x i32> %3, ptr %1, align 16
  ret void
}

define void @rotr_v4i32(<4 x i32> %0, ptr %1) {
; CHECK-LABEL: rotr_v4i32:
; CHECK:       // %bb.0:
; CHECK-NEXT:    shl v1.4s, v0.4s, #30
; CHECK-NEXT:    sri v1.4s, v0.4s, #2
; CHECK-NEXT:    str q1, [x0]
; CHECK-NEXT:    ret
  %3 = tail call <4 x i32> @llvm.fshl.v4i32(<4 x i32> %0, <4 x i32> %0, <4 x i32> <i32 -2, i32 -2, i32 -2, i32 -2>)
  store <4 x i32> %3, ptr %1, align 16
  ret void
}

define void @rotl_v1i64(<1 x i64> %0, ptr %1) {
; CHECK-LABEL: rotl_v1i64:
; CHECK:       // %bb.0:
; CHECK-NEXT:    shl d1, d0, #2
; CHECK-NEXT:    sri d1, d0, #62
; CHECK-NEXT:    str d1, [x0]
; CHECK-NEXT:    ret
  %3 = tail call <1 x i64> @llvm.fshl.v1i64(<1 x i64> %0, <1 x i64> %0, <1 x i64> <i64 2>)
  store <1 x i64> %3, ptr %1, align 16
  ret void
}

define void @rotr_v1i64(<1 x i64> %0, ptr %1) {
; CHECK-LABEL: rotr_v1i64:
; CHECK:       // %bb.0:
; CHECK-NEXT:    shl d1, d0, #62
; CHECK-NEXT:    sri d1, d0, #2
; CHECK-NEXT:    str d1, [x0]
; CHECK-NEXT:    ret
  %3 = tail call <1 x i64> @llvm.fshl.v1i64(<1 x i64> %0, <1 x i64> %0, <1 x i64> <i64 -2>)
  store <1 x i64> %3, ptr %1, align 16
  ret void
}

define void @rotl_v2i64(<2 x i64> %0, ptr %1) {
; CHECK-LABEL: rotl_v2i64:
; CHECK:       // %bb.0:
; CHECK-NEXT:    shl v1.2d, v0.2d, #2
; CHECK-NEXT:    sri v1.2d, v0.2d, #62
; CHECK-NEXT:    str q1, [x0]
; CHECK-NEXT:    ret
  %3 = tail call <2 x i64> @llvm.fshl.v2i64(<2 x i64> %0, <2 x i64> %0, <2 x i64> <i64 2, i64 2>)
  store <2 x i64> %3, ptr %1, align 16
  ret void
}

define void @rotr_v2i64(<2 x i64> %0, ptr %1) {
; CHECK-LABEL: rotr_v2i64:
; CHECK:       // %bb.0:
; CHECK-NEXT:    shl v1.2d, v0.2d, #62
; CHECK-NEXT:    sri v1.2d, v0.2d, #2
; CHECK-NEXT:    str q1, [x0]
; CHECK-NEXT:    ret
  %3 = tail call <2 x i64> @llvm.fshl.v2i64(<2 x i64> %0, <2 x i64> %0, <2 x i64> <i64 -2, i64 -2>)
  store <2 x i64> %3, ptr %1, align 16
  ret void
}

declare <8 x i8> @llvm.fshl.v8i8(<8 x i8> , <8 x i8> , <8 x i8> ) #0
declare <16 x i8> @llvm.fshl.v16i8(<16 x i8> , <16 x i8> , <16 x i8> ) #0
declare <4 x i16> @llvm.fshl.v4i16(<4 x i16>, <4 x i16>, <4 x i16>) #0
declare <8 x i16> @llvm.fshl.v8i16(<8 x i16>, <8 x i16>, <8 x i16>) #0
declare <2 x i32> @llvm.fshl.v2i32(<2 x i32>, <2 x i32>, <2 x i32>) #0
declare <4 x i32> @llvm.fshl.v4i32(<4 x i32>, <4 x i32>, <4 x i32>) #0
declare <1 x i64> @llvm.fshl.v1i64(<1 x i64>, <1 x i64>, <1 x i64>) #0
declare <2 x i64> @llvm.fshl.v2i64(<2 x i64>, <2 x i64>, <2 x i64>) #0

attributes #0 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }
