; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 2
; RUN: llc < %s -O2 -mtriple=aarch64 -mcpu=generic -aarch64-stp-policy=aligned | FileCheck %s

define ptr @stp_aligned_int32_t(ptr %0, i32 %1) #0 {
; CHECK-LABEL: stp_aligned_int32_t:
; CHECK:       // %bb.0:
; CHECK-NEXT:    and x0, x0, #0xffffffffffffffc0
; CHECK-NEXT:    stp w1, w1, [x0]
; CHECK-NEXT:    ret
  %3 = ptrtoint ptr %0 to i64
  %4 = and i64 %3, -64
  %5 = inttoptr i64 %4 to ptr
  store i32 %1, ptr %5, align 64
  %6 = getelementptr inbounds i32, ptr %5, i64 1
  store i32 %1, ptr %6, align 4
  ret ptr %5
}

define dso_local ptr @stp_aligned_int64_t(ptr %0, i64 %1) #0 {
; CHECK-LABEL: stp_aligned_int64_t:
; CHECK:       // %bb.0:
; CHECK-NEXT:    and x0, x0, #0xffffffffffffff80
; CHECK-NEXT:    stp x1, x1, [x0]
; CHECK-NEXT:    ret
  %3 = ptrtoint ptr %0 to i64
  %4 = and i64 %3, -128
  %5 = inttoptr i64 %4 to ptr
  store i64 %1, ptr %5, align 128
  %6 = getelementptr inbounds i64, ptr %5, i64 1
  store i64 %1, ptr %6, align 8
  ret ptr %5
}

define ptr @stp_aligned_v4si(ptr %0, <4 x i32> %1) #0 {
; CHECK-LABEL: stp_aligned_v4si:
; CHECK:       // %bb.0:
; CHECK-NEXT:    and x0, x0, #0xffffffffffffff00
; CHECK-NEXT:    stp q0, q0, [x0]
; CHECK-NEXT:    ret
  %3 = ptrtoint ptr %0 to i64
  %4 = and i64 %3, -256
  %5 = inttoptr i64 %4 to ptr
  store <4 x i32> %1, ptr %5, align 256
  %6 = getelementptr inbounds <4 x i32>, ptr %5, i64 1
  store <4 x i32> %1, ptr %6, align 16
  ret ptr %5
}

define ptr @stp_unaligned_int32_t(ptr %0, i32 %1) #0 {
; CHECK-LABEL: stp_unaligned_int32_t:
; CHECK:       // %bb.0:
; CHECK-NEXT:    and x8, x0, #0xffffffffffffffc0
; CHECK-NEXT:    orr x0, x8, #0x4
; CHECK-NEXT:    str w1, [x8, #4]
; CHECK-NEXT:    str w1, [x8, #8]
; CHECK-NEXT:    ret
  %3 = ptrtoint ptr %0 to i64
  %4 = and i64 %3, -64
  %5 = inttoptr i64 %4 to ptr
  %6 = getelementptr inbounds i32, ptr %5, i64 1
  store i32 %1, ptr %6, align 4
  %7 = getelementptr inbounds i32, ptr %5, i64 2
  store i32 %1, ptr %7, align 8
  ret ptr %6
}

define ptr @stp_unaligned_int64_t(ptr %0, i64 %1) #0 {
; CHECK-LABEL: stp_unaligned_int64_t:
; CHECK:       // %bb.0:
; CHECK-NEXT:    and x8, x0, #0xffffffffffffff80
; CHECK-NEXT:    orr x0, x8, #0x8
; CHECK-NEXT:    str x1, [x8, #8]
; CHECK-NEXT:    str x1, [x8, #16]
; CHECK-NEXT:    ret
  %3 = ptrtoint ptr %0 to i64
  %4 = and i64 %3, -128
  %5 = inttoptr i64 %4 to ptr
  %6 = getelementptr inbounds i64, ptr %5, i64 1
  store i64 %1, ptr %6, align 8
  %7 = getelementptr inbounds i64, ptr %5, i64 2
  store i64 %1, ptr %7, align 16
  ret ptr %6
}

define ptr @stp_unaligned_v4si(ptr %0, <4 x i32> %1) #0 {
; CHECK-LABEL: stp_unaligned_v4si:
; CHECK:       // %bb.0:
; CHECK-NEXT:    and x8, x0, #0xffffffffffffff00
; CHECK-NEXT:    orr x0, x8, #0x10
; CHECK-NEXT:    str q0, [x8, #16]
; CHECK-NEXT:    str q0, [x8, #32]
; CHECK-NEXT:    ret
  %3 = ptrtoint ptr %0 to i64
  %4 = and i64 %3, -256
  %5 = inttoptr i64 %4 to ptr
  %6 = getelementptr inbounds <4 x i32>, ptr %5, i64 1
  store <4 x i32> %1, ptr %6, align 16
  %7 = getelementptr inbounds <4 x i32>, ptr %5, i64 2
  store <4 x i32> %1, ptr %7, align 32
  ret ptr %6
}

