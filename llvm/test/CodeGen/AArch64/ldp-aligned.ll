; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 2
; RUN: llc < %s -O2 -mtriple=aarch64 -mcpu=generic -aarch64-ldp-policy=aligned | FileCheck %s

define i32 @ldp_aligned_int32_t(ptr %0) #0 {
; CHECK-LABEL: ldp_aligned_int32_t:
; CHECK:       // %bb.0:
; CHECK-NEXT:    and x8, x0, #0xffffffffffffffc0
; CHECK-NEXT:    ldp w9, w8, [x8]
; CHECK-NEXT:    add w0, w8, w9
; CHECK-NEXT:    ret
  %2 = ptrtoint ptr %0 to i64
  %3 = and i64 %2, -64
  %4 = inttoptr i64 %3 to ptr
  %5 = load i32, ptr %4, align 64
  %6 = getelementptr inbounds i32, ptr %4, i64 1
  %7 = load i32, ptr %6, align 4
  %8 = add nsw i32 %7, %5
  ret i32 %8
}

define i64 @ldp_aligned_int64_t(ptr %0) #0 {
; CHECK-LABEL: ldp_aligned_int64_t:
; CHECK:       // %bb.0:
; CHECK-NEXT:    and x8, x0, #0xffffffffffffff80
; CHECK-NEXT:    ldp x9, x8, [x8]
; CHECK-NEXT:    add x0, x8, x9
; CHECK-NEXT:    ret
  %2 = ptrtoint ptr %0 to i64
  %3 = and i64 %2, -128
  %4 = inttoptr i64 %3 to ptr
  %5 = load i64, ptr %4, align 128
  %6 = getelementptr inbounds i64, ptr %4, i64 1
  %7 = load i64, ptr %6, align 8
  %8 = add nsw i64 %7, %5
  ret i64 %8
}

define <4 x i32> @ldp_aligned_v4si(ptr %0) #0 {
; CHECK-LABEL: ldp_aligned_v4si:
; CHECK:       // %bb.0:
; CHECK-NEXT:    and x8, x0, #0xffffffffffffff00
; CHECK-NEXT:    ldp q0, q1, [x8]
; CHECK-NEXT:    add v0.4s, v1.4s, v0.4s
; CHECK-NEXT:    ret
  %2 = ptrtoint ptr %0 to i64
  %3 = and i64 %2, -256
  %4 = inttoptr i64 %3 to ptr
  %5 = load <4 x i32>, ptr %4, align 256
  %6 = getelementptr inbounds <4 x i32>, ptr %4, i64 1
  %7 = load <4 x i32>, ptr %6, align 16
  %8 = add <4 x i32> %7, %5
  ret <4 x i32> %8
}

define i32 @ldp_unaligned_int32_t(ptr %0) #0 {
; CHECK-LABEL: ldp_unaligned_int32_t:
; CHECK:       // %bb.0:
; CHECK-NEXT:    and x8, x0, #0xffffffffffffffc0
; CHECK-NEXT:    ldr w9, [x8, #4]
; CHECK-NEXT:    ldr w8, [x8, #8]
; CHECK-NEXT:    add w0, w8, w9
; CHECK-NEXT:    ret
  %2 = ptrtoint ptr %0 to i64
  %3 = and i64 %2, -64
  %4 = inttoptr i64 %3 to ptr
  %5 = getelementptr inbounds i32, ptr %4, i64 1
  %6 = load i32, ptr %5, align 4
  %7 = getelementptr inbounds i32, ptr %4, i64 2
  %8 = load i32, ptr %7, align 8
  %9 = add nsw i32 %8, %6
  ret i32 %9
}

define i64 @ldp_unaligned_int64_t(ptr %0) #0 {
; CHECK-LABEL: ldp_unaligned_int64_t:
; CHECK:       // %bb.0:
; CHECK-NEXT:    and x8, x0, #0xffffffffffffff80
; CHECK-NEXT:    ldr x9, [x8, #8]
; CHECK-NEXT:    ldr x8, [x8, #16]
; CHECK-NEXT:    add x0, x8, x9
; CHECK-NEXT:    ret
  %2 = ptrtoint ptr %0 to i64
  %3 = and i64 %2, -128
  %4 = inttoptr i64 %3 to ptr
  %5 = getelementptr inbounds i64, ptr %4, i64 1
  %6 = load i64, ptr %5, align 8
  %7 = getelementptr inbounds i64, ptr %4, i64 2
  %8 = load i64, ptr %7, align 16
  %9 = add nsw i64 %8, %6
  ret i64 %9
}

define <4 x i32> @ldp_unaligned_v4si(ptr %0) #0 {
; CHECK-LABEL: ldp_unaligned_v4si:
; CHECK:       // %bb.0:
; CHECK-NEXT:    and x8, x0, #0xffffffffffffff00
; CHECK-NEXT:    ldr q0, [x8, #16]
; CHECK-NEXT:    ldr q1, [x8, #32]
; CHECK-NEXT:    add v0.4s, v1.4s, v0.4s
; CHECK-NEXT:    ret
  %2 = ptrtoint ptr %0 to i64
  %3 = and i64 %2, -256
  %4 = inttoptr i64 %3 to ptr
  %5 = getelementptr inbounds <4 x i32>, ptr %4, i64 1
  %6 = load <4 x i32>, ptr %5, align 16
  %7 = getelementptr inbounds <4 x i32>, ptr %4, i64 2
  %8 = load <4 x i32>, ptr %7, align 32
  %9 = add <4 x i32> %8, %6
  ret <4 x i32> %9
}
