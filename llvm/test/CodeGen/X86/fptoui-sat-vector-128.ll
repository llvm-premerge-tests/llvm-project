; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s -mtriple=x86_64-- | FileCheck %s
; RUN: llc < %s -mtriple=x86_64-- -mattr=+avx512f,+avx512vl,+avx512dq,+avx512fp16 | FileCheck %s --check-prefixes=AVX512

;
; 32-bit float to unsigned integer
;

declare <4 x i1> @llvm.fptoui.sat.v4i1.v4f32(<4 x float>)
declare <4 x i8> @llvm.fptoui.sat.v4i8.v4f32(<4 x float>)
declare <4 x i16> @llvm.fptoui.sat.v4i16.v4f32(<4 x float>)
declare <4 x i32> @llvm.fptoui.sat.v4i32.v4f32(<4 x float>)
declare <4 x i64> @llvm.fptoui.sat.v4i64.v4f32(<4 x float>)
declare <4 x i128> @llvm.fptoui.sat.v4i128.v4f32(<4 x float>)

define <4 x i1> @test_unsigned_v4i1_v4f32(<4 x float> %f) nounwind {
; CHECK-LABEL: test_unsigned_v4i1_v4f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    xorps %xmm1, %xmm1
; CHECK-NEXT:    maxps %xmm1, %xmm0
; CHECK-NEXT:    minps {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cvttps2dq %xmm0, %xmm0
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_unsigned_v4i1_v4f32:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; AVX512-NEXT:    vmaxps %xmm0, %xmm1, %xmm0
; AVX512-NEXT:    vbroadcastss {{.*#+}} xmm1 = [1.0E+0,1.0E+0,1.0E+0,1.0E+0]
; AVX512-NEXT:    vminps %xmm0, %xmm1, %xmm0
; AVX512-NEXT:    vcvttps2dq %xmm0, %xmm0
; AVX512-NEXT:    vpslld $31, %xmm0, %xmm0
; AVX512-NEXT:    vpmovd2m %xmm0, %k0
; AVX512-NEXT:    vpmovm2d %k0, %xmm0
; AVX512-NEXT:    retq
  %x = call <4 x i1> @llvm.fptoui.sat.v4i1.v4f32(<4 x float> %f)
  ret <4 x i1> %x
}

define <4 x i8> @test_unsigned_v4i8_v4f32(<4 x float> %f) nounwind {
; CHECK-LABEL: test_unsigned_v4i8_v4f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    xorps %xmm1, %xmm1
; CHECK-NEXT:    maxps %xmm1, %xmm0
; CHECK-NEXT:    minps {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cvttps2dq %xmm0, %xmm0
; CHECK-NEXT:    packuswb %xmm0, %xmm0
; CHECK-NEXT:    packuswb %xmm0, %xmm0
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_unsigned_v4i8_v4f32:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; AVX512-NEXT:    vmaxps %xmm1, %xmm0, %xmm0
; AVX512-NEXT:    vminps {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to4}, %xmm0, %xmm0
; AVX512-NEXT:    vcvttps2dq %xmm0, %xmm0
; AVX512-NEXT:    vpmovdb %xmm0, %xmm0
; AVX512-NEXT:    retq
  %x = call <4 x i8> @llvm.fptoui.sat.v4i8.v4f32(<4 x float> %f)
  ret <4 x i8> %x
}

define <4 x i16> @test_unsigned_v4i16_v4f32(<4 x float> %f) nounwind {
; CHECK-LABEL: test_unsigned_v4i16_v4f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    xorps %xmm1, %xmm1
; CHECK-NEXT:    maxps %xmm1, %xmm0
; CHECK-NEXT:    minps {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cvttps2dq %xmm0, %xmm0
; CHECK-NEXT:    pshuflw {{.*#+}} xmm0 = xmm0[0,2,2,3,4,5,6,7]
; CHECK-NEXT:    pshufhw {{.*#+}} xmm0 = xmm0[0,1,2,3,4,6,6,7]
; CHECK-NEXT:    pshufd {{.*#+}} xmm0 = xmm0[0,2,2,3]
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_unsigned_v4i16_v4f32:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; AVX512-NEXT:    vmaxps %xmm1, %xmm0, %xmm0
; AVX512-NEXT:    vminps {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to4}, %xmm0, %xmm0
; AVX512-NEXT:    vcvttps2dq %xmm0, %xmm0
; AVX512-NEXT:    vpackusdw %xmm0, %xmm0, %xmm0
; AVX512-NEXT:    retq
  %x = call <4 x i16> @llvm.fptoui.sat.v4i16.v4f32(<4 x float> %f)
  ret <4 x i16> %x
}

define <4 x i32> @test_unsigned_v4i32_v4f32(<4 x float> %f) nounwind {
; CHECK-LABEL: test_unsigned_v4i32_v4f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    xorps %xmm2, %xmm2
; CHECK-NEXT:    cmpnleps %xmm0, %xmm2
; CHECK-NEXT:    cvttps2dq %xmm0, %xmm3
; CHECK-NEXT:    movdqa %xmm3, %xmm4
; CHECK-NEXT:    psrad $31, %xmm4
; CHECK-NEXT:    movaps {{.*#+}} xmm1 = [4.29496704E+9,4.29496704E+9,4.29496704E+9,4.29496704E+9]
; CHECK-NEXT:    cmpltps %xmm0, %xmm1
; CHECK-NEXT:    subps {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cvttps2dq %xmm0, %xmm0
; CHECK-NEXT:    pand %xmm4, %xmm0
; CHECK-NEXT:    por %xmm3, %xmm0
; CHECK-NEXT:    andnps %xmm0, %xmm2
; CHECK-NEXT:    orps %xmm2, %xmm1
; CHECK-NEXT:    movaps %xmm1, %xmm0
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_unsigned_v4i32_v4f32:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; AVX512-NEXT:    vcmpnleps %xmm0, %xmm1, %k0
; AVX512-NEXT:    knotw %k0, %k1
; AVX512-NEXT:    vcvttps2udq %xmm0, %xmm1 {%k1} {z}
; AVX512-NEXT:    vcmpgtps {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to4}, %xmm0, %k1
; AVX512-NEXT:    vpcmpeqd %xmm0, %xmm0, %xmm0
; AVX512-NEXT:    vmovdqa32 %xmm0, %xmm1 {%k1}
; AVX512-NEXT:    vmovdqa %xmm1, %xmm0
; AVX512-NEXT:    retq
  %x = call <4 x i32> @llvm.fptoui.sat.v4i32.v4f32(<4 x float> %f)
  ret <4 x i32> %x
}

define <4 x i64> @test_unsigned_v4i64_v4f32(<4 x float> %f) nounwind {
; CHECK-LABEL: test_unsigned_v4i64_v4f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movss {{.*#+}} xmm1 = mem[0],zero,zero,zero
; CHECK-NEXT:    movaps %xmm0, %xmm2
; CHECK-NEXT:    subss %xmm1, %xmm2
; CHECK-NEXT:    cvttss2si %xmm2, %rax
; CHECK-NEXT:    cvttss2si %xmm0, %rcx
; CHECK-NEXT:    movq %rcx, %rdx
; CHECK-NEXT:    sarq $63, %rdx
; CHECK-NEXT:    andq %rax, %rdx
; CHECK-NEXT:    orq %rcx, %rdx
; CHECK-NEXT:    xorl %eax, %eax
; CHECK-NEXT:    xorps %xmm3, %xmm3
; CHECK-NEXT:    ucomiss %xmm3, %xmm0
; CHECK-NEXT:    cmovbq %rax, %rdx
; CHECK-NEXT:    movss {{.*#+}} xmm4 = mem[0],zero,zero,zero
; CHECK-NEXT:    ucomiss %xmm4, %xmm0
; CHECK-NEXT:    movq $-1, %rcx
; CHECK-NEXT:    cmovaq %rcx, %rdx
; CHECK-NEXT:    movq %rdx, %xmm2
; CHECK-NEXT:    movaps %xmm0, %xmm5
; CHECK-NEXT:    shufps {{.*#+}} xmm5 = xmm5[1,1],xmm0[1,1]
; CHECK-NEXT:    movaps %xmm5, %xmm6
; CHECK-NEXT:    subss %xmm1, %xmm6
; CHECK-NEXT:    cvttss2si %xmm6, %rdx
; CHECK-NEXT:    cvttss2si %xmm5, %rsi
; CHECK-NEXT:    movq %rsi, %rdi
; CHECK-NEXT:    sarq $63, %rdi
; CHECK-NEXT:    andq %rdx, %rdi
; CHECK-NEXT:    orq %rsi, %rdi
; CHECK-NEXT:    ucomiss %xmm3, %xmm5
; CHECK-NEXT:    cmovbq %rax, %rdi
; CHECK-NEXT:    ucomiss %xmm4, %xmm5
; CHECK-NEXT:    cmovaq %rcx, %rdi
; CHECK-NEXT:    movq %rdi, %xmm5
; CHECK-NEXT:    punpcklqdq {{.*#+}} xmm2 = xmm2[0],xmm5[0]
; CHECK-NEXT:    movaps %xmm0, %xmm5
; CHECK-NEXT:    shufps {{.*#+}} xmm5 = xmm5[3,3],xmm0[3,3]
; CHECK-NEXT:    movaps %xmm5, %xmm6
; CHECK-NEXT:    subss %xmm1, %xmm6
; CHECK-NEXT:    cvttss2si %xmm6, %rdx
; CHECK-NEXT:    cvttss2si %xmm5, %rsi
; CHECK-NEXT:    movq %rsi, %rdi
; CHECK-NEXT:    sarq $63, %rdi
; CHECK-NEXT:    andq %rdx, %rdi
; CHECK-NEXT:    orq %rsi, %rdi
; CHECK-NEXT:    ucomiss %xmm3, %xmm5
; CHECK-NEXT:    cmovbq %rax, %rdi
; CHECK-NEXT:    ucomiss %xmm4, %xmm5
; CHECK-NEXT:    cmovaq %rcx, %rdi
; CHECK-NEXT:    movq %rdi, %xmm5
; CHECK-NEXT:    movhlps {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    movaps %xmm0, %xmm6
; CHECK-NEXT:    subss %xmm1, %xmm6
; CHECK-NEXT:    cvttss2si %xmm6, %rdx
; CHECK-NEXT:    cvttss2si %xmm0, %rsi
; CHECK-NEXT:    movq %rsi, %rdi
; CHECK-NEXT:    sarq $63, %rdi
; CHECK-NEXT:    andq %rdx, %rdi
; CHECK-NEXT:    orq %rsi, %rdi
; CHECK-NEXT:    ucomiss %xmm3, %xmm0
; CHECK-NEXT:    cmovbq %rax, %rdi
; CHECK-NEXT:    ucomiss %xmm4, %xmm0
; CHECK-NEXT:    cmovaq %rcx, %rdi
; CHECK-NEXT:    movq %rdi, %xmm1
; CHECK-NEXT:    punpcklqdq {{.*#+}} xmm1 = xmm1[0],xmm5[0]
; CHECK-NEXT:    movdqa %xmm2, %xmm0
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_unsigned_v4i64_v4f32:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; AVX512-NEXT:    vcmpnleps %xmm0, %xmm1, %k0
; AVX512-NEXT:    knotw %k0, %k1
; AVX512-NEXT:    vcvttps2uqq %xmm0, %ymm1 {%k1} {z}
; AVX512-NEXT:    vcmpgtps {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to4}, %xmm0, %k1
; AVX512-NEXT:    vpcmpeqd %ymm0, %ymm0, %ymm0
; AVX512-NEXT:    vmovdqa64 %ymm0, %ymm1 {%k1}
; AVX512-NEXT:    vmovdqa %ymm1, %ymm0
; AVX512-NEXT:    retq
  %x = call <4 x i64> @llvm.fptoui.sat.v4i64.v4f32(<4 x float> %f)
  ret <4 x i64> %x
}

define <4 x i128> @test_unsigned_v4i128_v4f32(<4 x float> %f) nounwind {
; CHECK-LABEL: test_unsigned_v4i128_v4f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    pushq %rbp
; CHECK-NEXT:    pushq %r15
; CHECK-NEXT:    pushq %r14
; CHECK-NEXT:    pushq %r13
; CHECK-NEXT:    pushq %r12
; CHECK-NEXT:    pushq %rbx
; CHECK-NEXT:    subq $56, %rsp
; CHECK-NEXT:    movaps %xmm0, (%rsp) # 16-byte Spill
; CHECK-NEXT:    movq %rdi, %rbx
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[1,1,1,1]
; CHECK-NEXT:    movaps %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    callq __fixunssfti@PLT
; CHECK-NEXT:    movq %rdx, %r15
; CHECK-NEXT:    xorl %r14d, %r14d
; CHECK-NEXT:    xorps %xmm0, %xmm0
; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Reload
; CHECK-NEXT:    ucomiss %xmm0, %xmm1
; CHECK-NEXT:    cmovbq %r14, %r15
; CHECK-NEXT:    cmovbq %r14, %rax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1
; CHECK-NEXT:    movq $-1, %rbp
; CHECK-NEXT:    cmovaq %rbp, %rax
; CHECK-NEXT:    movq %rax, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; CHECK-NEXT:    cmovaq %rbp, %r15
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    movhlps {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    movaps %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    callq __fixunssfti@PLT
; CHECK-NEXT:    movq %rax, %r12
; CHECK-NEXT:    movq %rdx, %r13
; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %r14, %r13
; CHECK-NEXT:    cmovbq %r14, %r12
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %rbp, %r12
; CHECK-NEXT:    cmovaq %rbp, %r13
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[3,3,3,3]
; CHECK-NEXT:    movaps %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    callq __fixunssfti@PLT
; CHECK-NEXT:    movq %rax, %rbp
; CHECK-NEXT:    movq %rdx, %r14
; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    movl $0, %eax
; CHECK-NEXT:    cmovbq %rax, %r14
; CHECK-NEXT:    cmovbq %rax, %rbp
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    movq $-1, %rax
; CHECK-NEXT:    cmovaq %rax, %rbp
; CHECK-NEXT:    cmovaq %rax, %r14
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    callq __fixunssfti@PLT
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    movl $0, %ecx
; CHECK-NEXT:    cmovbq %rcx, %rdx
; CHECK-NEXT:    cmovbq %rcx, %rax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    movq $-1, %rcx
; CHECK-NEXT:    cmovaq %rcx, %rax
; CHECK-NEXT:    cmovaq %rcx, %rdx
; CHECK-NEXT:    movq %rdx, 8(%rbx)
; CHECK-NEXT:    movq %rax, (%rbx)
; CHECK-NEXT:    movq %r14, 56(%rbx)
; CHECK-NEXT:    movq %rbp, 48(%rbx)
; CHECK-NEXT:    movq %r13, 40(%rbx)
; CHECK-NEXT:    movq %r12, 32(%rbx)
; CHECK-NEXT:    movq %r15, 24(%rbx)
; CHECK-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; CHECK-NEXT:    movq %rax, 16(%rbx)
; CHECK-NEXT:    movq %rbx, %rax
; CHECK-NEXT:    addq $56, %rsp
; CHECK-NEXT:    popq %rbx
; CHECK-NEXT:    popq %r12
; CHECK-NEXT:    popq %r13
; CHECK-NEXT:    popq %r14
; CHECK-NEXT:    popq %r15
; CHECK-NEXT:    popq %rbp
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_unsigned_v4i128_v4f32:
; AVX512:       # %bb.0:
; AVX512-NEXT:    pushq %rbp
; AVX512-NEXT:    pushq %r15
; AVX512-NEXT:    pushq %r14
; AVX512-NEXT:    pushq %r13
; AVX512-NEXT:    pushq %r12
; AVX512-NEXT:    pushq %rbx
; AVX512-NEXT:    subq $56, %rsp
; AVX512-NEXT:    vmovaps %xmm0, (%rsp) # 16-byte Spill
; AVX512-NEXT:    movq %rdi, %rbx
; AVX512-NEXT:    vmovshdup {{.*#+}} xmm0 = xmm0[1,1,3,3]
; AVX512-NEXT:    vmovaps %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; AVX512-NEXT:    callq __fixunssfti@PLT
; AVX512-NEXT:    movq %rdx, %r15
; AVX512-NEXT:    xorl %r14d, %r14d
; AVX512-NEXT:    vxorps %xmm0, %xmm0, %xmm0
; AVX512-NEXT:    vmovaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Reload
; AVX512-NEXT:    vucomiss %xmm0, %xmm1
; AVX512-NEXT:    cmovbq %r14, %r15
; AVX512-NEXT:    cmovbq %r14, %rax
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1
; AVX512-NEXT:    movq $-1, %rbp
; AVX512-NEXT:    cmovaq %rbp, %rax
; AVX512-NEXT:    movq %rax, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; AVX512-NEXT:    cmovaq %rbp, %r15
; AVX512-NEXT:    vpermilpd $1, (%rsp), %xmm0 # 16-byte Folded Reload
; AVX512-NEXT:    # xmm0 = mem[1,0]
; AVX512-NEXT:    vmovapd %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; AVX512-NEXT:    callq __fixunssfti@PLT
; AVX512-NEXT:    movq %rax, %r12
; AVX512-NEXT:    movq %rdx, %r13
; AVX512-NEXT:    vmovaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovbq %r14, %r13
; AVX512-NEXT:    cmovbq %r14, %r12
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovaq %rbp, %r12
; AVX512-NEXT:    cmovaq %rbp, %r13
; AVX512-NEXT:    vpermilps $255, (%rsp), %xmm0 # 16-byte Folded Reload
; AVX512-NEXT:    # xmm0 = mem[3,3,3,3]
; AVX512-NEXT:    vmovaps %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; AVX512-NEXT:    callq __fixunssfti@PLT
; AVX512-NEXT:    movq %rax, %rbp
; AVX512-NEXT:    movq %rdx, %r14
; AVX512-NEXT:    vmovaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    movl $0, %eax
; AVX512-NEXT:    cmovbq %rax, %r14
; AVX512-NEXT:    cmovbq %rax, %rbp
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    movq $-1, %rax
; AVX512-NEXT:    cmovaq %rax, %rbp
; AVX512-NEXT:    cmovaq %rax, %r14
; AVX512-NEXT:    vmovaps (%rsp), %xmm0 # 16-byte Reload
; AVX512-NEXT:    callq __fixunssfti@PLT
; AVX512-NEXT:    vmovaps (%rsp), %xmm0 # 16-byte Reload
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    movl $0, %ecx
; AVX512-NEXT:    cmovbq %rcx, %rdx
; AVX512-NEXT:    cmovbq %rcx, %rax
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    movq $-1, %rcx
; AVX512-NEXT:    cmovaq %rcx, %rax
; AVX512-NEXT:    cmovaq %rcx, %rdx
; AVX512-NEXT:    movq %rdx, 8(%rbx)
; AVX512-NEXT:    movq %rax, (%rbx)
; AVX512-NEXT:    movq %r14, 56(%rbx)
; AVX512-NEXT:    movq %rbp, 48(%rbx)
; AVX512-NEXT:    movq %r13, 40(%rbx)
; AVX512-NEXT:    movq %r12, 32(%rbx)
; AVX512-NEXT:    movq %r15, 24(%rbx)
; AVX512-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; AVX512-NEXT:    movq %rax, 16(%rbx)
; AVX512-NEXT:    movq %rbx, %rax
; AVX512-NEXT:    addq $56, %rsp
; AVX512-NEXT:    popq %rbx
; AVX512-NEXT:    popq %r12
; AVX512-NEXT:    popq %r13
; AVX512-NEXT:    popq %r14
; AVX512-NEXT:    popq %r15
; AVX512-NEXT:    popq %rbp
; AVX512-NEXT:    retq
  %x = call <4 x i128> @llvm.fptoui.sat.v4i128.v4f32(<4 x float> %f)
  ret <4 x i128> %x
}

;
; 64-bit float to unsigned integer
;

declare <2 x i1> @llvm.fptoui.sat.v2i1.v2f64(<2 x double>)
declare <2 x i8> @llvm.fptoui.sat.v2i8.v2f64(<2 x double>)
declare <2 x i16> @llvm.fptoui.sat.v2i16.v2f64(<2 x double>)
declare <2 x i32> @llvm.fptoui.sat.v2i32.v2f64(<2 x double>)
declare <2 x i64> @llvm.fptoui.sat.v2i64.v2f64(<2 x double>)
declare <2 x i128> @llvm.fptoui.sat.v2i128.v2f64(<2 x double>)

define <2 x i1> @test_unsigned_v2i1_v2f64(<2 x double> %f) nounwind {
; CHECK-LABEL: test_unsigned_v2i1_v2f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    xorpd %xmm2, %xmm2
; CHECK-NEXT:    movapd %xmm0, %xmm1
; CHECK-NEXT:    maxsd %xmm2, %xmm1
; CHECK-NEXT:    movsd {{.*#+}} xmm3 = mem[0],zero
; CHECK-NEXT:    minsd %xmm3, %xmm1
; CHECK-NEXT:    cvttsd2si %xmm1, %rax
; CHECK-NEXT:    movq %rax, %xmm1
; CHECK-NEXT:    unpckhpd {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    maxsd %xmm2, %xmm0
; CHECK-NEXT:    minsd %xmm3, %xmm0
; CHECK-NEXT:    cvttsd2si %xmm0, %rax
; CHECK-NEXT:    movq %rax, %xmm0
; CHECK-NEXT:    punpcklqdq {{.*#+}} xmm1 = xmm1[0],xmm0[0]
; CHECK-NEXT:    movdqa %xmm1, %xmm0
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_unsigned_v2i1_v2f64:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vxorpd %xmm1, %xmm1, %xmm1
; AVX512-NEXT:    vmaxpd %xmm0, %xmm1, %xmm0
; AVX512-NEXT:    vmovddup {{.*#+}} xmm1 = [1.0E+0,1.0E+0]
; AVX512-NEXT:    # xmm1 = mem[0,0]
; AVX512-NEXT:    vminpd %xmm0, %xmm1, %xmm0
; AVX512-NEXT:    vcvttpd2dq %xmm0, %xmm0
; AVX512-NEXT:    vpslld $31, %xmm0, %xmm0
; AVX512-NEXT:    vpmovd2m %xmm0, %k0
; AVX512-NEXT:    vpmovm2q %k0, %xmm0
; AVX512-NEXT:    retq
  %x = call <2 x i1> @llvm.fptoui.sat.v2i1.v2f64(<2 x double> %f)
  ret <2 x i1> %x
}

define <2 x i8> @test_unsigned_v2i8_v2f64(<2 x double> %f) nounwind {
; CHECK-LABEL: test_unsigned_v2i8_v2f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    xorpd %xmm2, %xmm2
; CHECK-NEXT:    movapd %xmm0, %xmm1
; CHECK-NEXT:    maxsd %xmm2, %xmm1
; CHECK-NEXT:    movsd {{.*#+}} xmm3 = mem[0],zero
; CHECK-NEXT:    minsd %xmm3, %xmm1
; CHECK-NEXT:    cvttsd2si %xmm1, %eax
; CHECK-NEXT:    movd %eax, %xmm1
; CHECK-NEXT:    unpckhpd {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    maxsd %xmm2, %xmm0
; CHECK-NEXT:    minsd %xmm3, %xmm0
; CHECK-NEXT:    cvttsd2si %xmm0, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    punpckldq {{.*#+}} xmm1 = xmm1[0],xmm0[0],xmm1[1],xmm0[1]
; CHECK-NEXT:    packuswb %xmm1, %xmm1
; CHECK-NEXT:    packuswb %xmm1, %xmm1
; CHECK-NEXT:    movdqa %xmm1, %xmm0
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_unsigned_v2i8_v2f64:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vmovapd %xmm0, %xmm0
; AVX512-NEXT:    vxorpd %xmm1, %xmm1, %xmm1
; AVX512-NEXT:    vmaxpd %ymm1, %ymm0, %ymm0
; AVX512-NEXT:    vminpd {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to4}, %ymm0, %ymm0
; AVX512-NEXT:    vcvttpd2dq %ymm0, %xmm0
; AVX512-NEXT:    vpmovdb %xmm0, %xmm0
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %x = call <2 x i8> @llvm.fptoui.sat.v2i8.v2f64(<2 x double> %f)
  ret <2 x i8> %x
}

define <2 x i16> @test_unsigned_v2i16_v2f64(<2 x double> %f) nounwind {
; CHECK-LABEL: test_unsigned_v2i16_v2f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    xorpd %xmm1, %xmm1
; CHECK-NEXT:    movapd %xmm0, %xmm2
; CHECK-NEXT:    maxsd %xmm1, %xmm2
; CHECK-NEXT:    movsd {{.*#+}} xmm3 = mem[0],zero
; CHECK-NEXT:    minsd %xmm3, %xmm2
; CHECK-NEXT:    cvttsd2si %xmm2, %eax
; CHECK-NEXT:    movd %eax, %xmm2
; CHECK-NEXT:    unpckhpd {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    maxsd %xmm1, %xmm0
; CHECK-NEXT:    minsd %xmm3, %xmm0
; CHECK-NEXT:    cvttsd2si %xmm0, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    punpckldq {{.*#+}} xmm2 = xmm2[0],xmm0[0],xmm2[1],xmm0[1]
; CHECK-NEXT:    pshuflw {{.*#+}} xmm0 = xmm2[0,2,2,3,4,5,6,7]
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_unsigned_v2i16_v2f64:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vmovapd %xmm0, %xmm0
; AVX512-NEXT:    vxorpd %xmm1, %xmm1, %xmm1
; AVX512-NEXT:    vmaxpd %ymm1, %ymm0, %ymm0
; AVX512-NEXT:    vminpd {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to4}, %ymm0, %ymm0
; AVX512-NEXT:    vcvttpd2dq %ymm0, %xmm0
; AVX512-NEXT:    vpackusdw %xmm0, %xmm0, %xmm0
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %x = call <2 x i16> @llvm.fptoui.sat.v2i16.v2f64(<2 x double> %f)
  ret <2 x i16> %x
}

define <2 x i32> @test_unsigned_v2i32_v2f64(<2 x double> %f) nounwind {
; CHECK-LABEL: test_unsigned_v2i32_v2f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    xorpd %xmm2, %xmm2
; CHECK-NEXT:    xorpd %xmm1, %xmm1
; CHECK-NEXT:    maxsd %xmm0, %xmm1
; CHECK-NEXT:    movsd {{.*#+}} xmm3 = mem[0],zero
; CHECK-NEXT:    movapd %xmm3, %xmm4
; CHECK-NEXT:    minsd %xmm1, %xmm4
; CHECK-NEXT:    cvttsd2si %xmm4, %rax
; CHECK-NEXT:    movd %eax, %xmm1
; CHECK-NEXT:    unpckhpd {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    maxsd %xmm0, %xmm2
; CHECK-NEXT:    minsd %xmm2, %xmm3
; CHECK-NEXT:    cvttsd2si %xmm3, %rax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    punpckldq {{.*#+}} xmm1 = xmm1[0],xmm0[0],xmm1[1],xmm0[1]
; CHECK-NEXT:    movdqa %xmm1, %xmm0
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_unsigned_v2i32_v2f64:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vmovapd %xmm0, %xmm0
; AVX512-NEXT:    vxorpd %xmm1, %xmm1, %xmm1
; AVX512-NEXT:    vmaxpd %ymm1, %ymm0, %ymm0
; AVX512-NEXT:    vminpd {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to4}, %ymm0, %ymm0
; AVX512-NEXT:    vcvttpd2udq %ymm0, %xmm0
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %x = call <2 x i32> @llvm.fptoui.sat.v2i32.v2f64(<2 x double> %f)
  ret <2 x i32> %x
}

define <2 x i64> @test_unsigned_v2i64_v2f64(<2 x double> %f) nounwind {
; CHECK-LABEL: test_unsigned_v2i64_v2f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    movapd %xmm0, %xmm1
; CHECK-NEXT:    subsd %xmm2, %xmm1
; CHECK-NEXT:    cvttsd2si %xmm1, %rax
; CHECK-NEXT:    cvttsd2si %xmm0, %rcx
; CHECK-NEXT:    movq %rcx, %rdx
; CHECK-NEXT:    sarq $63, %rdx
; CHECK-NEXT:    andq %rax, %rdx
; CHECK-NEXT:    orq %rcx, %rdx
; CHECK-NEXT:    xorl %eax, %eax
; CHECK-NEXT:    xorpd %xmm3, %xmm3
; CHECK-NEXT:    ucomisd %xmm3, %xmm0
; CHECK-NEXT:    cmovbq %rax, %rdx
; CHECK-NEXT:    movsd {{.*#+}} xmm4 = mem[0],zero
; CHECK-NEXT:    ucomisd %xmm4, %xmm0
; CHECK-NEXT:    movq $-1, %rcx
; CHECK-NEXT:    cmovaq %rcx, %rdx
; CHECK-NEXT:    movq %rdx, %xmm1
; CHECK-NEXT:    unpckhpd {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    movapd %xmm0, %xmm5
; CHECK-NEXT:    subsd %xmm2, %xmm5
; CHECK-NEXT:    cvttsd2si %xmm5, %rdx
; CHECK-NEXT:    cvttsd2si %xmm0, %rsi
; CHECK-NEXT:    movq %rsi, %rdi
; CHECK-NEXT:    sarq $63, %rdi
; CHECK-NEXT:    andq %rdx, %rdi
; CHECK-NEXT:    orq %rsi, %rdi
; CHECK-NEXT:    ucomisd %xmm3, %xmm0
; CHECK-NEXT:    cmovbq %rax, %rdi
; CHECK-NEXT:    ucomisd %xmm4, %xmm0
; CHECK-NEXT:    cmovaq %rcx, %rdi
; CHECK-NEXT:    movq %rdi, %xmm0
; CHECK-NEXT:    punpcklqdq {{.*#+}} xmm1 = xmm1[0],xmm0[0]
; CHECK-NEXT:    movdqa %xmm1, %xmm0
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_unsigned_v2i64_v2f64:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vxorpd %xmm1, %xmm1, %xmm1
; AVX512-NEXT:    vcmpnlepd %xmm0, %xmm1, %k0
; AVX512-NEXT:    knotw %k0, %k1
; AVX512-NEXT:    vcvttpd2uqq %xmm0, %xmm1 {%k1} {z}
; AVX512-NEXT:    vcmpgtpd {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to2}, %xmm0, %k1
; AVX512-NEXT:    vpcmpeqd %xmm0, %xmm0, %xmm0
; AVX512-NEXT:    vmovdqa64 %xmm0, %xmm1 {%k1}
; AVX512-NEXT:    vmovdqa %xmm1, %xmm0
; AVX512-NEXT:    retq
  %x = call <2 x i64> @llvm.fptoui.sat.v2i64.v2f64(<2 x double> %f)
  ret <2 x i64> %x
}

define <2 x i128> @test_unsigned_v2i128_v2f64(<2 x double> %f) nounwind {
; CHECK-LABEL: test_unsigned_v2i128_v2f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    pushq %r15
; CHECK-NEXT:    pushq %r14
; CHECK-NEXT:    pushq %r13
; CHECK-NEXT:    pushq %r12
; CHECK-NEXT:    pushq %rbx
; CHECK-NEXT:    subq $32, %rsp
; CHECK-NEXT:    movapd %xmm0, (%rsp) # 16-byte Spill
; CHECK-NEXT:    movq %rdi, %rbx
; CHECK-NEXT:    unpckhpd {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    movapd %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    callq __fixunsdfti@PLT
; CHECK-NEXT:    movq %rax, %r14
; CHECK-NEXT:    movq %rdx, %r15
; CHECK-NEXT:    xorl %r12d, %r12d
; CHECK-NEXT:    xorpd %xmm0, %xmm0
; CHECK-NEXT:    movapd {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Reload
; CHECK-NEXT:    ucomisd %xmm0, %xmm1
; CHECK-NEXT:    cmovbq %r12, %r15
; CHECK-NEXT:    cmovbq %r12, %r14
; CHECK-NEXT:    ucomisd {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1
; CHECK-NEXT:    movq $-1, %r13
; CHECK-NEXT:    cmovaq %r13, %r14
; CHECK-NEXT:    cmovaq %r13, %r15
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    callq __fixunsdfti@PLT
; CHECK-NEXT:    movapd (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    ucomisd {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %r12, %rdx
; CHECK-NEXT:    cmovbq %r12, %rax
; CHECK-NEXT:    ucomisd {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %r13, %rax
; CHECK-NEXT:    cmovaq %r13, %rdx
; CHECK-NEXT:    movq %rdx, 8(%rbx)
; CHECK-NEXT:    movq %rax, (%rbx)
; CHECK-NEXT:    movq %r15, 24(%rbx)
; CHECK-NEXT:    movq %r14, 16(%rbx)
; CHECK-NEXT:    movq %rbx, %rax
; CHECK-NEXT:    addq $32, %rsp
; CHECK-NEXT:    popq %rbx
; CHECK-NEXT:    popq %r12
; CHECK-NEXT:    popq %r13
; CHECK-NEXT:    popq %r14
; CHECK-NEXT:    popq %r15
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_unsigned_v2i128_v2f64:
; AVX512:       # %bb.0:
; AVX512-NEXT:    pushq %r15
; AVX512-NEXT:    pushq %r14
; AVX512-NEXT:    pushq %r13
; AVX512-NEXT:    pushq %r12
; AVX512-NEXT:    pushq %rbx
; AVX512-NEXT:    subq $32, %rsp
; AVX512-NEXT:    vmovapd %xmm0, (%rsp) # 16-byte Spill
; AVX512-NEXT:    movq %rdi, %rbx
; AVX512-NEXT:    vshufpd {{.*#+}} xmm0 = xmm0[1,0]
; AVX512-NEXT:    vmovapd %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; AVX512-NEXT:    callq __fixunsdfti@PLT
; AVX512-NEXT:    movq %rax, %r14
; AVX512-NEXT:    movq %rdx, %r15
; AVX512-NEXT:    xorl %r12d, %r12d
; AVX512-NEXT:    vxorpd %xmm0, %xmm0, %xmm0
; AVX512-NEXT:    vmovapd {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Reload
; AVX512-NEXT:    vucomisd %xmm0, %xmm1
; AVX512-NEXT:    cmovbq %r12, %r15
; AVX512-NEXT:    cmovbq %r12, %r14
; AVX512-NEXT:    vucomisd {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1
; AVX512-NEXT:    movq $-1, %r13
; AVX512-NEXT:    cmovaq %r13, %r14
; AVX512-NEXT:    cmovaq %r13, %r15
; AVX512-NEXT:    vmovaps (%rsp), %xmm0 # 16-byte Reload
; AVX512-NEXT:    callq __fixunsdfti@PLT
; AVX512-NEXT:    vmovapd (%rsp), %xmm0 # 16-byte Reload
; AVX512-NEXT:    vucomisd {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovbq %r12, %rdx
; AVX512-NEXT:    cmovbq %r12, %rax
; AVX512-NEXT:    vucomisd {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovaq %r13, %rax
; AVX512-NEXT:    cmovaq %r13, %rdx
; AVX512-NEXT:    movq %rdx, 8(%rbx)
; AVX512-NEXT:    movq %rax, (%rbx)
; AVX512-NEXT:    movq %r15, 24(%rbx)
; AVX512-NEXT:    movq %r14, 16(%rbx)
; AVX512-NEXT:    movq %rbx, %rax
; AVX512-NEXT:    addq $32, %rsp
; AVX512-NEXT:    popq %rbx
; AVX512-NEXT:    popq %r12
; AVX512-NEXT:    popq %r13
; AVX512-NEXT:    popq %r14
; AVX512-NEXT:    popq %r15
; AVX512-NEXT:    retq
  %x = call <2 x i128> @llvm.fptoui.sat.v2i128.v2f64(<2 x double> %f)
  ret <2 x i128> %x
}

;
; 16-bit float to unsigned integer
;

declare <8 x i1> @llvm.fptoui.sat.v8i1.v8f16(<8 x half>)
declare <8 x i8> @llvm.fptoui.sat.v8i8.v8f16(<8 x half>)
declare <8 x i16> @llvm.fptoui.sat.v8i16.v8f16(<8 x half>)
declare <8 x i32> @llvm.fptoui.sat.v8i32.v8f16(<8 x half>)
declare <8 x i64> @llvm.fptoui.sat.v8i64.v8f16(<8 x half>)
declare <8 x i128> @llvm.fptoui.sat.v8i128.v8f16(<8 x half>)

define <8 x i1> @test_unsigned_v8i1_v8f16(<8 x half> %f) nounwind {
; CHECK-LABEL: test_unsigned_v8i1_v8f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    pushq %rbp
; CHECK-NEXT:    pushq %rbx
; CHECK-NEXT:    subq $72, %rsp
; CHECK-NEXT:    movdqa %xmm0, (%rsp) # 16-byte Spill
; CHECK-NEXT:    psrldq {{.*#+}} xmm0 = xmm0[14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    xorl %ebx, %ebx
; CHECK-NEXT:    xorps %xmm1, %xmm1
; CHECK-NEXT:    ucomiss %xmm1, %xmm0
; CHECK-NEXT:    cmovbl %ebx, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    movl $1, %ebp
; CHECK-NEXT:    cmoval %ebp, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[3,3,3,3]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebx, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebp, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    punpcklwd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1],xmm0[2],mem[2],xmm0[3],mem[3]
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrldq {{.*#+}} xmm0 = xmm0[10,11,12,13,14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebx, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebp, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    movhlps {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebx, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebp, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    punpcklwd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1],xmm0[2],mem[2],xmm0[3],mem[3]
; CHECK-NEXT:    punpckldq {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1]
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrlq $48, %xmm0
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebx, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebp, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[1,1,1,1]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebx, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebp, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    punpcklwd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1],xmm0[2],mem[2],xmm0[3],mem[3]
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebx, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebp, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrld $16, %xmm0
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebx, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebp, %eax
; CHECK-NEXT:    movd %eax, %xmm1
; CHECK-NEXT:    movdqa {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    punpcklwd {{.*#+}} xmm0 = xmm0[0],xmm1[0],xmm0[1],xmm1[1],xmm0[2],xmm1[2],xmm0[3],xmm1[3]
; CHECK-NEXT:    punpckldq {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1]
; CHECK-NEXT:    punpcklqdq {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0]
; CHECK-NEXT:    addq $72, %rsp
; CHECK-NEXT:    popq %rbx
; CHECK-NEXT:    popq %rbp
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_unsigned_v8i1_v8f16:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; AVX512-NEXT:    vmaxph %xmm0, %xmm1, %xmm0
; AVX512-NEXT:    vpbroadcastw {{.*#+}} xmm1 = [1.0E+0,1.0E+0,1.0E+0,1.0E+0,1.0E+0,1.0E+0,1.0E+0,1.0E+0]
; AVX512-NEXT:    vminph %xmm0, %xmm1, %xmm0
; AVX512-NEXT:    vcvttph2dq %xmm0, %ymm0
; AVX512-NEXT:    vpslld $31, %ymm0, %ymm0
; AVX512-NEXT:    vpmovd2m %ymm0, %k0
; AVX512-NEXT:    vpmovm2w %k0, %xmm0
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %x = call <8 x i1> @llvm.fptoui.sat.v8i1.v8f16(<8 x half> %f)
  ret <8 x i1> %x
}

define <8 x i8> @test_unsigned_v8i8_v8f16(<8 x half> %f) nounwind {
; CHECK-LABEL: test_unsigned_v8i8_v8f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    subq $72, %rsp
; CHECK-NEXT:    movdqa %xmm0, (%rsp) # 16-byte Spill
; CHECK-NEXT:    psrldq {{.*#+}} xmm0 = xmm0[14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[3,3,3,3]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    unpcklps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1]
; CHECK-NEXT:    movaps %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrldq {{.*#+}} xmm0 = xmm0[10,11,12,13,14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    movhlps {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    unpcklps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1]
; CHECK-NEXT:    unpcklpd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0]
; CHECK-NEXT:    xorps %xmm1, %xmm1
; CHECK-NEXT:    maxps %xmm1, %xmm0
; CHECK-NEXT:    minps {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cvttps2dq %xmm0, %xmm0
; CHECK-NEXT:    movaps %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrlq $48, %xmm0
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[1,1,1,1]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    unpcklps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1]
; CHECK-NEXT:    movaps %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movaps %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrld $16, %xmm0
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movdqa {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Reload
; CHECK-NEXT:    punpckldq {{.*#+}} xmm1 = xmm1[0],xmm0[0],xmm1[1],xmm0[1]
; CHECK-NEXT:    punpcklqdq {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm1 = xmm1[0],mem[0]
; CHECK-NEXT:    maxps {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1
; CHECK-NEXT:    minps {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1
; CHECK-NEXT:    cvttps2dq %xmm1, %xmm0
; CHECK-NEXT:    packuswb {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    packuswb %xmm0, %xmm0
; CHECK-NEXT:    addq $72, %rsp
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_unsigned_v8i8_v8f16:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; AVX512-NEXT:    vmaxph %xmm0, %xmm1, %xmm0
; AVX512-NEXT:    vpbroadcastw {{.*#+}} xmm1 = [2.55E+2,2.55E+2,2.55E+2,2.55E+2,2.55E+2,2.55E+2,2.55E+2,2.55E+2]
; AVX512-NEXT:    vminph %xmm0, %xmm1, %xmm0
; AVX512-NEXT:    vcvttph2dq %xmm0, %ymm0
; AVX512-NEXT:    vpmovdw %ymm0, %xmm0
; AVX512-NEXT:    vpackuswb %xmm0, %xmm0, %xmm0
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %x = call <8 x i8> @llvm.fptoui.sat.v8i8.v8f16(<8 x half> %f)
  ret <8 x i8> %x
}

define <8 x i16> @test_unsigned_v8i16_v8f16(<8 x half> %f) nounwind {
; CHECK-LABEL: test_unsigned_v8i16_v8f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    pushq %rbp
; CHECK-NEXT:    pushq %rbx
; CHECK-NEXT:    subq $72, %rsp
; CHECK-NEXT:    movdqa %xmm0, (%rsp) # 16-byte Spill
; CHECK-NEXT:    psrldq {{.*#+}} xmm0 = xmm0[14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    xorl %ebx, %ebx
; CHECK-NEXT:    xorps %xmm1, %xmm1
; CHECK-NEXT:    ucomiss %xmm1, %xmm0
; CHECK-NEXT:    cmovbl %ebx, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    movl $65535, %ebp # imm = 0xFFFF
; CHECK-NEXT:    cmoval %ebp, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[3,3,3,3]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebx, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebp, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    punpcklwd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1],xmm0[2],mem[2],xmm0[3],mem[3]
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrldq {{.*#+}} xmm0 = xmm0[10,11,12,13,14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebx, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebp, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    movhlps {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebx, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebp, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    punpcklwd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1],xmm0[2],mem[2],xmm0[3],mem[3]
; CHECK-NEXT:    punpckldq {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1]
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrlq $48, %xmm0
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebx, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebp, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[1,1,1,1]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebx, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebp, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    punpcklwd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1],xmm0[2],mem[2],xmm0[3],mem[3]
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebx, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebp, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrld $16, %xmm0
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebx, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebp, %eax
; CHECK-NEXT:    movd %eax, %xmm1
; CHECK-NEXT:    movdqa {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    punpcklwd {{.*#+}} xmm0 = xmm0[0],xmm1[0],xmm0[1],xmm1[1],xmm0[2],xmm1[2],xmm0[3],xmm1[3]
; CHECK-NEXT:    punpckldq {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1]
; CHECK-NEXT:    punpcklqdq {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0]
; CHECK-NEXT:    addq $72, %rsp
; CHECK-NEXT:    popq %rbx
; CHECK-NEXT:    popq %rbp
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_unsigned_v8i16_v8f16:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; AVX512-NEXT:    vcmpnleph %xmm0, %xmm1, %k0
; AVX512-NEXT:    knotb %k0, %k1
; AVX512-NEXT:    vcvttph2dq %xmm0, %ymm1
; AVX512-NEXT:    vpmovdw %ymm1, %xmm1 {%k1} {z}
; AVX512-NEXT:    vcmpgtph {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to8}, %xmm0, %k1
; AVX512-NEXT:    vpcmpeqd %xmm0, %xmm0, %xmm0
; AVX512-NEXT:    vmovdqu16 %xmm0, %xmm1 {%k1}
; AVX512-NEXT:    vmovdqa %xmm1, %xmm0
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %x = call <8 x i16> @llvm.fptoui.sat.v8i16.v8f16(<8 x half> %f)
  ret <8 x i16> %x
}

define <8 x i32> @test_unsigned_v8i32_v8f16(<8 x half> %f) nounwind {
; CHECK-LABEL: test_unsigned_v8i32_v8f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    subq $72, %rsp
; CHECK-NEXT:    movdqa %xmm0, (%rsp) # 16-byte Spill
; CHECK-NEXT:    psrlq $48, %xmm0
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[1,1,1,1]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    unpcklps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1]
; CHECK-NEXT:    cvttps2dq %xmm0, %xmm1
; CHECK-NEXT:    movdqa %xmm1, %xmm2
; CHECK-NEXT:    psrad $31, %xmm2
; CHECK-NEXT:    xorps %xmm3, %xmm3
; CHECK-NEXT:    cmpnleps %xmm0, %xmm3
; CHECK-NEXT:    movaps {{.*#+}} xmm5 = [4.29496704E+9,4.29496704E+9,4.29496704E+9,4.29496704E+9]
; CHECK-NEXT:    cmpltps %xmm0, %xmm5
; CHECK-NEXT:    subps {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cvttps2dq %xmm0, %xmm0
; CHECK-NEXT:    pand %xmm2, %xmm0
; CHECK-NEXT:    por %xmm1, %xmm0
; CHECK-NEXT:    andnps %xmm0, %xmm3
; CHECK-NEXT:    orps %xmm3, %xmm5
; CHECK-NEXT:    movaps %xmm5, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movaps %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrld $16, %xmm0
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movdqa {{[-0-9]+}}(%r{{[sb]}}p), %xmm3 # 16-byte Reload
; CHECK-NEXT:    punpckldq {{.*#+}} xmm3 = xmm3[0],xmm0[0],xmm3[1],xmm0[1]
; CHECK-NEXT:    cvttps2dq %xmm3, %xmm0
; CHECK-NEXT:    movdqa %xmm0, %xmm1
; CHECK-NEXT:    psrad $31, %xmm1
; CHECK-NEXT:    movdqa %xmm3, %xmm2
; CHECK-NEXT:    subps {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm2
; CHECK-NEXT:    cvttps2dq %xmm2, %xmm2
; CHECK-NEXT:    pand %xmm1, %xmm2
; CHECK-NEXT:    por %xmm0, %xmm2
; CHECK-NEXT:    pxor %xmm0, %xmm0
; CHECK-NEXT:    cmpnleps %xmm3, %xmm0
; CHECK-NEXT:    andnps %xmm2, %xmm0
; CHECK-NEXT:    movaps {{.*#+}} xmm1 = [4.29496704E+9,4.29496704E+9,4.29496704E+9,4.29496704E+9]
; CHECK-NEXT:    cmpltps %xmm3, %xmm1
; CHECK-NEXT:    orps %xmm0, %xmm1
; CHECK-NEXT:    unpcklpd {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm1 = xmm1[0],mem[0]
; CHECK-NEXT:    movaps %xmm1, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrldq {{.*#+}} xmm0 = xmm0[14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[3,3,3,3]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    unpcklps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1]
; CHECK-NEXT:    cvttps2dq %xmm0, %xmm1
; CHECK-NEXT:    movdqa %xmm1, %xmm2
; CHECK-NEXT:    psrad $31, %xmm2
; CHECK-NEXT:    xorps %xmm3, %xmm3
; CHECK-NEXT:    cmpnleps %xmm0, %xmm3
; CHECK-NEXT:    movaps {{.*#+}} xmm4 = [4.29496704E+9,4.29496704E+9,4.29496704E+9,4.29496704E+9]
; CHECK-NEXT:    cmpltps %xmm0, %xmm4
; CHECK-NEXT:    subps {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cvttps2dq %xmm0, %xmm0
; CHECK-NEXT:    pand %xmm2, %xmm0
; CHECK-NEXT:    por %xmm1, %xmm0
; CHECK-NEXT:    andnps %xmm0, %xmm3
; CHECK-NEXT:    orps %xmm3, %xmm4
; CHECK-NEXT:    movaps %xmm4, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrldq {{.*#+}} xmm0 = xmm0[10,11,12,13,14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    movhlps {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    unpcklps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1]
; CHECK-NEXT:    cvttps2dq %xmm0, %xmm1
; CHECK-NEXT:    movdqa %xmm1, %xmm2
; CHECK-NEXT:    psrad $31, %xmm2
; CHECK-NEXT:    xorps %xmm4, %xmm4
; CHECK-NEXT:    cmpnleps %xmm0, %xmm4
; CHECK-NEXT:    movaps {{.*#+}} xmm3 = [4.29496704E+9,4.29496704E+9,4.29496704E+9,4.29496704E+9]
; CHECK-NEXT:    cmpltps %xmm0, %xmm3
; CHECK-NEXT:    subps {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cvttps2dq %xmm0, %xmm0
; CHECK-NEXT:    pand %xmm2, %xmm0
; CHECK-NEXT:    por %xmm1, %xmm0
; CHECK-NEXT:    andnps %xmm0, %xmm4
; CHECK-NEXT:    movaps %xmm3, %xmm1
; CHECK-NEXT:    orps %xmm4, %xmm1
; CHECK-NEXT:    unpcklpd {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm1 = xmm1[0],mem[0]
; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    addq $72, %rsp
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_unsigned_v8i32_v8f16:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; AVX512-NEXT:    vcmpnleph %xmm0, %xmm1, %k0
; AVX512-NEXT:    knotb %k0, %k1
; AVX512-NEXT:    vcvttph2udq %xmm0, %ymm1 {%k1} {z}
; AVX512-NEXT:    vcmpgtph {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to8}, %xmm0, %k1
; AVX512-NEXT:    vpcmpeqd %ymm0, %ymm0, %ymm0
; AVX512-NEXT:    vmovdqa32 %ymm0, %ymm1 {%k1}
; AVX512-NEXT:    vmovdqa %ymm1, %ymm0
; AVX512-NEXT:    retq
  %x = call <8 x i32> @llvm.fptoui.sat.v8i32.v8f16(<8 x half> %f)
  ret <8 x i32> %x
}

define <8 x i64> @test_unsigned_v8i64_v8f16(<8 x half> %f) nounwind {
; CHECK-LABEL: test_unsigned_v8i64_v8f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    pushq %r14
; CHECK-NEXT:    pushq %rbx
; CHECK-NEXT:    subq $88, %rsp
; CHECK-NEXT:    movaps %xmm0, (%rsp) # 16-byte Spill
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movaps %xmm0, %xmm1
; CHECK-NEXT:    subss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1
; CHECK-NEXT:    cvttss2si %xmm1, %rax
; CHECK-NEXT:    cvttss2si %xmm0, %rcx
; CHECK-NEXT:    movq %rcx, %rdx
; CHECK-NEXT:    sarq $63, %rdx
; CHECK-NEXT:    andq %rax, %rdx
; CHECK-NEXT:    orq %rcx, %rdx
; CHECK-NEXT:    xorl %ebx, %ebx
; CHECK-NEXT:    xorps %xmm1, %xmm1
; CHECK-NEXT:    ucomiss %xmm1, %xmm0
; CHECK-NEXT:    cmovbq %rbx, %rdx
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    movq $-1, %r14
; CHECK-NEXT:    cmovaq %r14, %rdx
; CHECK-NEXT:    movq %rdx, %xmm0
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrld $16, %xmm0
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movdqa %xmm0, %xmm1
; CHECK-NEXT:    subss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1
; CHECK-NEXT:    cvttss2si %xmm1, %rax
; CHECK-NEXT:    cvttss2si %xmm0, %rcx
; CHECK-NEXT:    movq %rcx, %rdx
; CHECK-NEXT:    sarq $63, %rdx
; CHECK-NEXT:    andq %rax, %rdx
; CHECK-NEXT:    orq %rcx, %rdx
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %rbx, %rdx
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %r14, %rdx
; CHECK-NEXT:    movq %rdx, %xmm0
; CHECK-NEXT:    movdqa {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Reload
; CHECK-NEXT:    punpcklqdq {{.*#+}} xmm1 = xmm1[0],xmm0[0]
; CHECK-NEXT:    movdqa %xmm1, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrlq $48, %xmm0
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movdqa %xmm0, %xmm1
; CHECK-NEXT:    subss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1
; CHECK-NEXT:    cvttss2si %xmm1, %rax
; CHECK-NEXT:    cvttss2si %xmm0, %rcx
; CHECK-NEXT:    movq %rcx, %rdx
; CHECK-NEXT:    sarq $63, %rdx
; CHECK-NEXT:    andq %rax, %rdx
; CHECK-NEXT:    orq %rcx, %rdx
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %rbx, %rdx
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %r14, %rdx
; CHECK-NEXT:    movq %rdx, %xmm0
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[1,1,1,1]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movaps %xmm0, %xmm1
; CHECK-NEXT:    subss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1
; CHECK-NEXT:    cvttss2si %xmm1, %rax
; CHECK-NEXT:    cvttss2si %xmm0, %rcx
; CHECK-NEXT:    movq %rcx, %rdx
; CHECK-NEXT:    sarq $63, %rdx
; CHECK-NEXT:    andq %rax, %rdx
; CHECK-NEXT:    orq %rcx, %rdx
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %rbx, %rdx
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %r14, %rdx
; CHECK-NEXT:    movq %rdx, %xmm0
; CHECK-NEXT:    punpcklqdq {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0]
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrldq {{.*#+}} xmm0 = xmm0[10,11,12,13,14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movdqa %xmm0, %xmm1
; CHECK-NEXT:    subss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1
; CHECK-NEXT:    cvttss2si %xmm1, %rax
; CHECK-NEXT:    cvttss2si %xmm0, %rcx
; CHECK-NEXT:    movq %rcx, %rdx
; CHECK-NEXT:    sarq $63, %rdx
; CHECK-NEXT:    andq %rax, %rdx
; CHECK-NEXT:    orq %rcx, %rdx
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %rbx, %rdx
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %r14, %rdx
; CHECK-NEXT:    movq %rdx, %xmm0
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    movhlps {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movaps %xmm0, %xmm1
; CHECK-NEXT:    subss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1
; CHECK-NEXT:    cvttss2si %xmm1, %rax
; CHECK-NEXT:    cvttss2si %xmm0, %rcx
; CHECK-NEXT:    movq %rcx, %rdx
; CHECK-NEXT:    sarq $63, %rdx
; CHECK-NEXT:    andq %rax, %rdx
; CHECK-NEXT:    orq %rcx, %rdx
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %rbx, %rdx
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %r14, %rdx
; CHECK-NEXT:    movq %rdx, %xmm0
; CHECK-NEXT:    punpcklqdq {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0]
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrldq {{.*#+}} xmm0 = xmm0[14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movdqa %xmm0, %xmm1
; CHECK-NEXT:    subss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1
; CHECK-NEXT:    cvttss2si %xmm1, %rax
; CHECK-NEXT:    cvttss2si %xmm0, %rcx
; CHECK-NEXT:    movq %rcx, %rdx
; CHECK-NEXT:    sarq $63, %rdx
; CHECK-NEXT:    andq %rax, %rdx
; CHECK-NEXT:    orq %rcx, %rdx
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %rbx, %rdx
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %r14, %rdx
; CHECK-NEXT:    movq %rdx, %xmm0
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[3,3,3,3]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movaps %xmm0, %xmm1
; CHECK-NEXT:    subss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1
; CHECK-NEXT:    cvttss2si %xmm1, %rax
; CHECK-NEXT:    cvttss2si %xmm0, %rcx
; CHECK-NEXT:    movq %rcx, %rdx
; CHECK-NEXT:    sarq $63, %rdx
; CHECK-NEXT:    andq %rax, %rdx
; CHECK-NEXT:    orq %rcx, %rdx
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %rbx, %rdx
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %r14, %rdx
; CHECK-NEXT:    movq %rdx, %xmm3
; CHECK-NEXT:    punpcklqdq {{[-0-9]+}}(%r{{[sb]}}p), %xmm3 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm3 = xmm3[0],mem[0]
; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Reload
; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm2 # 16-byte Reload
; CHECK-NEXT:    addq $88, %rsp
; CHECK-NEXT:    popq %rbx
; CHECK-NEXT:    popq %r14
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_unsigned_v8i64_v8f16:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; AVX512-NEXT:    vcmpnleph %xmm0, %xmm1, %k0
; AVX512-NEXT:    knotb %k0, %k1
; AVX512-NEXT:    vcvttph2uqq %xmm0, %zmm1 {%k1} {z}
; AVX512-NEXT:    vcmpgtph {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to8}, %xmm0, %k1
; AVX512-NEXT:    vpternlogd $255, %zmm0, %zmm0, %zmm0
; AVX512-NEXT:    vmovdqa64 %zmm0, %zmm1 {%k1}
; AVX512-NEXT:    vmovdqa64 %zmm1, %zmm0
; AVX512-NEXT:    retq
  %x = call <8 x i64> @llvm.fptoui.sat.v8i64.v8f16(<8 x half> %f)
  ret <8 x i64> %x
}

define <8 x i128> @test_unsigned_v8i128_v8f16(<8 x half> %f) nounwind {
; CHECK-LABEL: test_unsigned_v8i128_v8f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    pushq %rbp
; CHECK-NEXT:    pushq %r15
; CHECK-NEXT:    pushq %r14
; CHECK-NEXT:    pushq %r13
; CHECK-NEXT:    pushq %r12
; CHECK-NEXT:    pushq %rbx
; CHECK-NEXT:    subq $104, %rsp
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movq %rdi, %rbx
; CHECK-NEXT:    psrld $16, %xmm0
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movd %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Folded Spill
; CHECK-NEXT:    callq __fixunssfti@PLT
; CHECK-NEXT:    xorl %r12d, %r12d
; CHECK-NEXT:    pxor %xmm0, %xmm0
; CHECK-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 4-byte Reload
; CHECK-NEXT:    # xmm1 = mem[0],zero,zero,zero
; CHECK-NEXT:    ucomiss %xmm0, %xmm1
; CHECK-NEXT:    cmovbq %r12, %rdx
; CHECK-NEXT:    cmovbq %r12, %rax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1
; CHECK-NEXT:    movq $-1, %r13
; CHECK-NEXT:    cmovaq %r13, %rax
; CHECK-NEXT:    movq %rax, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; CHECK-NEXT:    cmovaq %r13, %rdx
; CHECK-NEXT:    movq %rdx, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[1,1,1,1]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; CHECK-NEXT:    callq __fixunssfti@PLT
; CHECK-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %r12, %rdx
; CHECK-NEXT:    cmovbq %r12, %rax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %r13, %rax
; CHECK-NEXT:    movq %rax, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; CHECK-NEXT:    cmovaq %r13, %rdx
; CHECK-NEXT:    movq %rdx, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; CHECK-NEXT:    movdqa {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrlq $48, %xmm0
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movd %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Folded Spill
; CHECK-NEXT:    callq __fixunssfti@PLT
; CHECK-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %r12, %rdx
; CHECK-NEXT:    cmovbq %r12, %rax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %r13, %rax
; CHECK-NEXT:    movq %rax, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; CHECK-NEXT:    cmovaq %r13, %rdx
; CHECK-NEXT:    movq %rdx, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    movhlps {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; CHECK-NEXT:    callq __fixunssfti@PLT
; CHECK-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %r12, %rdx
; CHECK-NEXT:    cmovbq %r12, %rax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %r13, %rax
; CHECK-NEXT:    movq %rax, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; CHECK-NEXT:    cmovaq %r13, %rdx
; CHECK-NEXT:    movq %rdx, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; CHECK-NEXT:    movdqa {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrldq {{.*#+}} xmm0 = xmm0[10,11,12,13,14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movd %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Folded Spill
; CHECK-NEXT:    callq __fixunssfti@PLT
; CHECK-NEXT:    movq %rdx, %rbp
; CHECK-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %r12, %rbp
; CHECK-NEXT:    cmovbq %r12, %rax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %r13, %rax
; CHECK-NEXT:    movq %rax, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; CHECK-NEXT:    cmovaq %r13, %rbp
; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[3,3,3,3]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; CHECK-NEXT:    callq __fixunssfti@PLT
; CHECK-NEXT:    movq %rax, %r14
; CHECK-NEXT:    movq %rdx, %r15
; CHECK-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %r12, %r15
; CHECK-NEXT:    cmovbq %r12, %r14
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %r13, %r14
; CHECK-NEXT:    cmovaq %r13, %r15
; CHECK-NEXT:    movdqa {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrldq {{.*#+}} xmm0 = xmm0[14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movd %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Folded Spill
; CHECK-NEXT:    callq __fixunssfti@PLT
; CHECK-NEXT:    movq %rax, %r12
; CHECK-NEXT:    movq %rdx, %r13
; CHECK-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    movl $0, %eax
; CHECK-NEXT:    cmovbq %rax, %r13
; CHECK-NEXT:    cmovbq %rax, %r12
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    movq $-1, %rax
; CHECK-NEXT:    cmovaq %rax, %r12
; CHECK-NEXT:    cmovaq %rax, %r13
; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; CHECK-NEXT:    callq __fixunssfti@PLT
; CHECK-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    movl $0, %ecx
; CHECK-NEXT:    cmovbq %rcx, %rdx
; CHECK-NEXT:    cmovbq %rcx, %rax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    movq $-1, %rcx
; CHECK-NEXT:    cmovaq %rcx, %rax
; CHECK-NEXT:    cmovaq %rcx, %rdx
; CHECK-NEXT:    movq %rdx, 8(%rbx)
; CHECK-NEXT:    movq %rax, (%rbx)
; CHECK-NEXT:    movq %r13, 120(%rbx)
; CHECK-NEXT:    movq %r12, 112(%rbx)
; CHECK-NEXT:    movq %r15, 104(%rbx)
; CHECK-NEXT:    movq %r14, 96(%rbx)
; CHECK-NEXT:    movq %rbp, 88(%rbx)
; CHECK-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; CHECK-NEXT:    movq %rax, 80(%rbx)
; CHECK-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; CHECK-NEXT:    movq %rax, 72(%rbx)
; CHECK-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; CHECK-NEXT:    movq %rax, 64(%rbx)
; CHECK-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; CHECK-NEXT:    movq %rax, 56(%rbx)
; CHECK-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; CHECK-NEXT:    movq %rax, 48(%rbx)
; CHECK-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; CHECK-NEXT:    movq %rax, 40(%rbx)
; CHECK-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; CHECK-NEXT:    movq %rax, 32(%rbx)
; CHECK-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; CHECK-NEXT:    movq %rax, 24(%rbx)
; CHECK-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; CHECK-NEXT:    movq %rax, 16(%rbx)
; CHECK-NEXT:    movq %rbx, %rax
; CHECK-NEXT:    addq $104, %rsp
; CHECK-NEXT:    popq %rbx
; CHECK-NEXT:    popq %r12
; CHECK-NEXT:    popq %r13
; CHECK-NEXT:    popq %r14
; CHECK-NEXT:    popq %r15
; CHECK-NEXT:    popq %rbp
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_unsigned_v8i128_v8f16:
; AVX512:       # %bb.0:
; AVX512-NEXT:    pushq %rbp
; AVX512-NEXT:    pushq %r15
; AVX512-NEXT:    pushq %r14
; AVX512-NEXT:    pushq %r13
; AVX512-NEXT:    pushq %r12
; AVX512-NEXT:    pushq %rbx
; AVX512-NEXT:    subq $104, %rsp
; AVX512-NEXT:    vmovdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; AVX512-NEXT:    movq %rdi, %rbx
; AVX512-NEXT:    vpsrld $16, %xmm0, %xmm1
; AVX512-NEXT:    vcvtsh2ss %xmm1, %xmm1, %xmm0
; AVX512-NEXT:    vmovss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; AVX512-NEXT:    callq __fixunssfti@PLT
; AVX512-NEXT:    xorl %r12d, %r12d
; AVX512-NEXT:    vxorps %xmm0, %xmm0, %xmm0
; AVX512-NEXT:    vmovss {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 4-byte Reload
; AVX512-NEXT:    # xmm1 = mem[0],zero,zero,zero
; AVX512-NEXT:    vucomiss %xmm0, %xmm1
; AVX512-NEXT:    cmovbq %r12, %rdx
; AVX512-NEXT:    cmovbq %r12, %rax
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1
; AVX512-NEXT:    movq $-1, %r13
; AVX512-NEXT:    cmovaq %r13, %rax
; AVX512-NEXT:    movq %rax, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; AVX512-NEXT:    cmovaq %r13, %rdx
; AVX512-NEXT:    movq %rdx, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; AVX512-NEXT:    vmovshdup {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; AVX512-NEXT:    # xmm0 = mem[1,1,3,3]
; AVX512-NEXT:    vcvtsh2ss %xmm0, %xmm0, %xmm0
; AVX512-NEXT:    vmovss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; AVX512-NEXT:    callq __fixunssfti@PLT
; AVX512-NEXT:    vmovss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; AVX512-NEXT:    # xmm0 = mem[0],zero,zero,zero
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovbq %r12, %rdx
; AVX512-NEXT:    cmovbq %r12, %rax
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovaq %r13, %rax
; AVX512-NEXT:    movq %rax, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; AVX512-NEXT:    cmovaq %r13, %rdx
; AVX512-NEXT:    movq %rdx, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; AVX512-NEXT:    vpsrlq $48, {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; AVX512-NEXT:    vcvtsh2ss %xmm0, %xmm0, %xmm0
; AVX512-NEXT:    vmovss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; AVX512-NEXT:    callq __fixunssfti@PLT
; AVX512-NEXT:    vmovss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; AVX512-NEXT:    # xmm0 = mem[0],zero,zero,zero
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovbq %r12, %rdx
; AVX512-NEXT:    cmovbq %r12, %rax
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovaq %r13, %rax
; AVX512-NEXT:    movq %rax, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; AVX512-NEXT:    cmovaq %r13, %rdx
; AVX512-NEXT:    movq %rdx, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; AVX512-NEXT:    vpermilpd $1, {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; AVX512-NEXT:    # xmm0 = mem[1,0]
; AVX512-NEXT:    vcvtsh2ss %xmm0, %xmm0, %xmm0
; AVX512-NEXT:    vmovss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; AVX512-NEXT:    callq __fixunssfti@PLT
; AVX512-NEXT:    vmovss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; AVX512-NEXT:    # xmm0 = mem[0],zero,zero,zero
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovbq %r12, %rdx
; AVX512-NEXT:    cmovbq %r12, %rax
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovaq %r13, %rax
; AVX512-NEXT:    movq %rax, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; AVX512-NEXT:    cmovaq %r13, %rdx
; AVX512-NEXT:    movq %rdx, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; AVX512-NEXT:    vpsrldq $10, {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; AVX512-NEXT:    # xmm0 = mem[10,11,12,13,14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; AVX512-NEXT:    vcvtsh2ss %xmm0, %xmm0, %xmm0
; AVX512-NEXT:    vmovss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; AVX512-NEXT:    callq __fixunssfti@PLT
; AVX512-NEXT:    movq %rdx, %rbp
; AVX512-NEXT:    vmovss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; AVX512-NEXT:    # xmm0 = mem[0],zero,zero,zero
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovbq %r12, %rbp
; AVX512-NEXT:    cmovbq %r12, %rax
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovaq %r13, %rax
; AVX512-NEXT:    movq %rax, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; AVX512-NEXT:    cmovaq %r13, %rbp
; AVX512-NEXT:    vpermilps $255, {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; AVX512-NEXT:    # xmm0 = mem[3,3,3,3]
; AVX512-NEXT:    vcvtsh2ss %xmm0, %xmm0, %xmm0
; AVX512-NEXT:    vmovss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; AVX512-NEXT:    callq __fixunssfti@PLT
; AVX512-NEXT:    movq %rax, %r14
; AVX512-NEXT:    movq %rdx, %r15
; AVX512-NEXT:    vmovss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; AVX512-NEXT:    # xmm0 = mem[0],zero,zero,zero
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovbq %r12, %r15
; AVX512-NEXT:    cmovbq %r12, %r14
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovaq %r13, %r14
; AVX512-NEXT:    cmovaq %r13, %r15
; AVX512-NEXT:    vpsrldq $14, {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; AVX512-NEXT:    # xmm0 = mem[14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; AVX512-NEXT:    vcvtsh2ss %xmm0, %xmm0, %xmm0
; AVX512-NEXT:    vmovss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; AVX512-NEXT:    callq __fixunssfti@PLT
; AVX512-NEXT:    movq %rax, %r12
; AVX512-NEXT:    movq %rdx, %r13
; AVX512-NEXT:    vmovss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; AVX512-NEXT:    # xmm0 = mem[0],zero,zero,zero
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    movl $0, %eax
; AVX512-NEXT:    cmovbq %rax, %r13
; AVX512-NEXT:    cmovbq %rax, %r12
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    movq $-1, %rax
; AVX512-NEXT:    cmovaq %rax, %r12
; AVX512-NEXT:    cmovaq %rax, %r13
; AVX512-NEXT:    vmovaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; AVX512-NEXT:    vcvtsh2ss %xmm0, %xmm0, %xmm0
; AVX512-NEXT:    vmovss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; AVX512-NEXT:    callq __fixunssfti@PLT
; AVX512-NEXT:    vmovss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; AVX512-NEXT:    # xmm0 = mem[0],zero,zero,zero
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    movl $0, %ecx
; AVX512-NEXT:    cmovbq %rcx, %rdx
; AVX512-NEXT:    cmovbq %rcx, %rax
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    movq $-1, %rcx
; AVX512-NEXT:    cmovaq %rcx, %rax
; AVX512-NEXT:    cmovaq %rcx, %rdx
; AVX512-NEXT:    movq %rdx, 8(%rbx)
; AVX512-NEXT:    movq %rax, (%rbx)
; AVX512-NEXT:    movq %r13, 120(%rbx)
; AVX512-NEXT:    movq %r12, 112(%rbx)
; AVX512-NEXT:    movq %r15, 104(%rbx)
; AVX512-NEXT:    movq %r14, 96(%rbx)
; AVX512-NEXT:    movq %rbp, 88(%rbx)
; AVX512-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; AVX512-NEXT:    movq %rax, 80(%rbx)
; AVX512-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; AVX512-NEXT:    movq %rax, 72(%rbx)
; AVX512-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; AVX512-NEXT:    movq %rax, 64(%rbx)
; AVX512-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; AVX512-NEXT:    movq %rax, 56(%rbx)
; AVX512-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; AVX512-NEXT:    movq %rax, 48(%rbx)
; AVX512-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; AVX512-NEXT:    movq %rax, 40(%rbx)
; AVX512-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; AVX512-NEXT:    movq %rax, 32(%rbx)
; AVX512-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; AVX512-NEXT:    movq %rax, 24(%rbx)
; AVX512-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; AVX512-NEXT:    movq %rax, 16(%rbx)
; AVX512-NEXT:    movq %rbx, %rax
; AVX512-NEXT:    addq $104, %rsp
; AVX512-NEXT:    popq %rbx
; AVX512-NEXT:    popq %r12
; AVX512-NEXT:    popq %r13
; AVX512-NEXT:    popq %r14
; AVX512-NEXT:    popq %r15
; AVX512-NEXT:    popq %rbp
; AVX512-NEXT:    retq
  %x = call <8 x i128> @llvm.fptoui.sat.v8i128.v8f16(<8 x half> %f)
  ret <8 x i128> %x
}
