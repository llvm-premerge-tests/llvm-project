; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s -mtriple=x86_64-- | FileCheck %s
; RUN: llc < %s -mtriple=x86_64-- -mattr=+avx512f,+avx512vl,+avx512dq,+avx512fp16 | FileCheck %s --check-prefixes=AVX512

;
; 32-bit float to signed integer
;

declare <4 x i1> @llvm.fptosi.sat.v4i1.v4f32(<4 x float>)
declare <4 x i8> @llvm.fptosi.sat.v4i8.v4f32(<4 x float>)
declare <4 x i16> @llvm.fptosi.sat.v4i16.v4f32(<4 x float>)
declare <4 x i32> @llvm.fptosi.sat.v4i32.v4f32(<4 x float>)
declare <4 x i64> @llvm.fptosi.sat.v4i64.v4f32(<4 x float>)
declare <4 x i128> @llvm.fptosi.sat.v4i128.v4f32(<4 x float>)

define <4 x i1> @test_signed_v4i1_v4f32(<4 x float> %f) nounwind {
; CHECK-LABEL: test_signed_v4i1_v4f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movaps %xmm0, %xmm1
; CHECK-NEXT:    maxps {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1
; CHECK-NEXT:    xorps %xmm2, %xmm2
; CHECK-NEXT:    minps %xmm1, %xmm2
; CHECK-NEXT:    cvttps2dq %xmm2, %xmm1
; CHECK-NEXT:    cmpunordps %xmm0, %xmm0
; CHECK-NEXT:    andnps %xmm1, %xmm0
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_signed_v4i1_v4f32:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vbroadcastss {{.*#+}} xmm1 = [-1.0E+0,-1.0E+0,-1.0E+0,-1.0E+0]
; AVX512-NEXT:    vmaxps %xmm0, %xmm1, %xmm0
; AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; AVX512-NEXT:    vminps %xmm0, %xmm1, %xmm0
; AVX512-NEXT:    vcvttps2dq %xmm0, %xmm0
; AVX512-NEXT:    vpslld $31, %xmm0, %xmm0
; AVX512-NEXT:    vpmovd2m %xmm0, %k0
; AVX512-NEXT:    vpmovm2d %k0, %xmm0
; AVX512-NEXT:    retq
  %x = call <4 x i1> @llvm.fptosi.sat.v4i1.v4f32(<4 x float> %f)
  ret <4 x i1> %x
}

define <4 x i8> @test_signed_v4i8_v4f32(<4 x float> %f) nounwind {
; CHECK-LABEL: test_signed_v4i8_v4f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movaps %xmm0, %xmm1
; CHECK-NEXT:    cmpunordps %xmm0, %xmm1
; CHECK-NEXT:    maxps {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    minps {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cvttps2dq %xmm0, %xmm0
; CHECK-NEXT:    andnps %xmm0, %xmm1
; CHECK-NEXT:    packuswb %xmm1, %xmm1
; CHECK-NEXT:    packuswb %xmm1, %xmm1
; CHECK-NEXT:    movdqa %xmm1, %xmm0
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_signed_v4i8_v4f32:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vmaxps {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to4}, %xmm0, %xmm1
; AVX512-NEXT:    vminps {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to4}, %xmm1, %xmm1
; AVX512-NEXT:    vcmpunordps %xmm0, %xmm0, %k0
; AVX512-NEXT:    knotw %k0, %k1
; AVX512-NEXT:    vcvttps2dq %xmm1, %xmm0 {%k1} {z}
; AVX512-NEXT:    vpmovdb %xmm0, %xmm0
; AVX512-NEXT:    retq
  %x = call <4 x i8> @llvm.fptosi.sat.v4i8.v4f32(<4 x float> %f)
  ret <4 x i8> %x
}

define <4 x i16> @test_signed_v4i16_v4f32(<4 x float> %f) nounwind {
; CHECK-LABEL: test_signed_v4i16_v4f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movaps %xmm0, %xmm1
; CHECK-NEXT:    cmpunordps %xmm0, %xmm1
; CHECK-NEXT:    maxps {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    minps {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cvttps2dq %xmm0, %xmm0
; CHECK-NEXT:    andnps %xmm0, %xmm1
; CHECK-NEXT:    pshuflw {{.*#+}} xmm0 = xmm1[0,2,2,3,4,5,6,7]
; CHECK-NEXT:    pshufhw {{.*#+}} xmm0 = xmm0[0,1,2,3,4,6,6,7]
; CHECK-NEXT:    pshufd {{.*#+}} xmm0 = xmm0[0,2,2,3]
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_signed_v4i16_v4f32:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vmaxps {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to4}, %xmm0, %xmm1
; AVX512-NEXT:    vminps {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to4}, %xmm1, %xmm1
; AVX512-NEXT:    vcmpunordps %xmm0, %xmm0, %k0
; AVX512-NEXT:    knotw %k0, %k1
; AVX512-NEXT:    vcvttps2dq %xmm1, %xmm0 {%k1} {z}
; AVX512-NEXT:    vpackusdw %xmm0, %xmm0, %xmm0
; AVX512-NEXT:    retq
  %x = call <4 x i16> @llvm.fptosi.sat.v4i16.v4f32(<4 x float> %f)
  ret <4 x i16> %x
}

define <4 x i32> @test_signed_v4i32_v4f32(<4 x float> %f) nounwind {
; CHECK-LABEL: test_signed_v4i32_v4f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movaps {{.*#+}} xmm1 = [2.14748352E+9,2.14748352E+9,2.14748352E+9,2.14748352E+9]
; CHECK-NEXT:    cmpltps %xmm0, %xmm1
; CHECK-NEXT:    cvttps2dq %xmm0, %xmm2
; CHECK-NEXT:    movaps %xmm1, %xmm3
; CHECK-NEXT:    andnps %xmm2, %xmm3
; CHECK-NEXT:    andps {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1
; CHECK-NEXT:    orps %xmm3, %xmm1
; CHECK-NEXT:    cmpunordps %xmm0, %xmm0
; CHECK-NEXT:    andnps %xmm1, %xmm0
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_signed_v4i32_v4f32:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vcmpgtps {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to4}, %xmm0, %k1
; AVX512-NEXT:    vcvttps2dq %xmm0, %xmm1
; AVX512-NEXT:    vpbroadcastd {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1 {%k1}
; AVX512-NEXT:    vcmpunordps %xmm0, %xmm0, %k0
; AVX512-NEXT:    knotw %k0, %k1
; AVX512-NEXT:    vmovdqa32 %xmm1, %xmm0 {%k1} {z}
; AVX512-NEXT:    retq
  %x = call <4 x i32> @llvm.fptosi.sat.v4i32.v4f32(<4 x float> %f)
  ret <4 x i32> %x
}

define <4 x i64> @test_signed_v4i64_v4f32(<4 x float> %f) nounwind {
; CHECK-LABEL: test_signed_v4i64_v4f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    cvttss2si %xmm0, %rdx
; CHECK-NEXT:    movss {{.*#+}} xmm1 = mem[0],zero,zero,zero
; CHECK-NEXT:    ucomiss %xmm1, %xmm0
; CHECK-NEXT:    movabsq $9223372036854775807, %rax # imm = 0x7FFFFFFFFFFFFFFF
; CHECK-NEXT:    cmovaq %rax, %rdx
; CHECK-NEXT:    xorl %ecx, %ecx
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpq %rcx, %rdx
; CHECK-NEXT:    movq %rdx, %xmm2
; CHECK-NEXT:    movaps %xmm0, %xmm3
; CHECK-NEXT:    shufps {{.*#+}} xmm3 = xmm3[1,1],xmm0[1,1]
; CHECK-NEXT:    cvttss2si %xmm3, %rdx
; CHECK-NEXT:    ucomiss %xmm1, %xmm3
; CHECK-NEXT:    cmovaq %rax, %rdx
; CHECK-NEXT:    ucomiss %xmm3, %xmm3
; CHECK-NEXT:    cmovpq %rcx, %rdx
; CHECK-NEXT:    movq %rdx, %xmm3
; CHECK-NEXT:    punpcklqdq {{.*#+}} xmm2 = xmm2[0],xmm3[0]
; CHECK-NEXT:    movaps %xmm0, %xmm3
; CHECK-NEXT:    shufps {{.*#+}} xmm3 = xmm3[3,3],xmm0[3,3]
; CHECK-NEXT:    cvttss2si %xmm3, %rdx
; CHECK-NEXT:    ucomiss %xmm1, %xmm3
; CHECK-NEXT:    cmovaq %rax, %rdx
; CHECK-NEXT:    ucomiss %xmm3, %xmm3
; CHECK-NEXT:    cmovpq %rcx, %rdx
; CHECK-NEXT:    movq %rdx, %xmm3
; CHECK-NEXT:    movhlps {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    cvttss2si %xmm0, %rdx
; CHECK-NEXT:    ucomiss %xmm1, %xmm0
; CHECK-NEXT:    cmovaq %rax, %rdx
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpq %rcx, %rdx
; CHECK-NEXT:    movq %rdx, %xmm1
; CHECK-NEXT:    punpcklqdq {{.*#+}} xmm1 = xmm1[0],xmm3[0]
; CHECK-NEXT:    movdqa %xmm2, %xmm0
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_signed_v4i64_v4f32:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vcmpgtps {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to4}, %xmm0, %k1
; AVX512-NEXT:    vcvttps2qq %xmm0, %ymm1
; AVX512-NEXT:    vpbroadcastq {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %ymm1 {%k1}
; AVX512-NEXT:    vcmpunordps %xmm0, %xmm0, %k0
; AVX512-NEXT:    knotw %k0, %k1
; AVX512-NEXT:    vmovdqa64 %ymm1, %ymm0 {%k1} {z}
; AVX512-NEXT:    retq
  %x = call <4 x i64> @llvm.fptosi.sat.v4i64.v4f32(<4 x float> %f)
  ret <4 x i64> %x
}

define <4 x i128> @test_signed_v4i128_v4f32(<4 x float> %f) nounwind {
; CHECK-LABEL: test_signed_v4i128_v4f32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    pushq %rbp
; CHECK-NEXT:    pushq %r15
; CHECK-NEXT:    pushq %r14
; CHECK-NEXT:    pushq %r13
; CHECK-NEXT:    pushq %r12
; CHECK-NEXT:    pushq %rbx
; CHECK-NEXT:    subq $56, %rsp
; CHECK-NEXT:    movaps %xmm0, (%rsp) # 16-byte Spill
; CHECK-NEXT:    movq %rdi, %rbx
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[1,1,1,1]
; CHECK-NEXT:    movaps %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    callq __fixsfti@PLT
; CHECK-NEXT:    movq %rdx, %r15
; CHECK-NEXT:    xorl %r14d, %r14d
; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %r14, %rax
; CHECK-NEXT:    movabsq $-9223372036854775808, %rcx # imm = 0x8000000000000000
; CHECK-NEXT:    cmovbq %rcx, %r15
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    movabsq $9223372036854775807, %rbp # imm = 0x7FFFFFFFFFFFFFFF
; CHECK-NEXT:    cmovaq %rbp, %r15
; CHECK-NEXT:    movq $-1, %rcx
; CHECK-NEXT:    cmovaq %rcx, %rax
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpq %r14, %rax
; CHECK-NEXT:    movq %rax, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; CHECK-NEXT:    cmovpq %r14, %r15
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    movhlps {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    movaps %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    callq __fixsfti@PLT
; CHECK-NEXT:    movq %rax, %r12
; CHECK-NEXT:    movq %rdx, %r13
; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %r14, %r12
; CHECK-NEXT:    movabsq $-9223372036854775808, %rax # imm = 0x8000000000000000
; CHECK-NEXT:    cmovbq %rax, %r13
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %rbp, %r13
; CHECK-NEXT:    movq $-1, %rax
; CHECK-NEXT:    cmovaq %rax, %r12
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpq %r14, %r12
; CHECK-NEXT:    cmovpq %r14, %r13
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[3,3,3,3]
; CHECK-NEXT:    movaps %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    callq __fixsfti@PLT
; CHECK-NEXT:    movq %rax, %rbp
; CHECK-NEXT:    movq %rdx, %r14
; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    movl $0, %eax
; CHECK-NEXT:    cmovbq %rax, %rbp
; CHECK-NEXT:    movabsq $-9223372036854775808, %rcx # imm = 0x8000000000000000
; CHECK-NEXT:    cmovbq %rcx, %r14
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    movabsq $9223372036854775807, %rcx # imm = 0x7FFFFFFFFFFFFFFF
; CHECK-NEXT:    cmovaq %rcx, %r14
; CHECK-NEXT:    movq $-1, %rcx
; CHECK-NEXT:    cmovaq %rcx, %rbp
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpq %rax, %rbp
; CHECK-NEXT:    cmovpq %rax, %r14
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    callq __fixsfti@PLT
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    movl $0, %esi
; CHECK-NEXT:    cmovbq %rsi, %rax
; CHECK-NEXT:    movabsq $-9223372036854775808, %rcx # imm = 0x8000000000000000
; CHECK-NEXT:    cmovbq %rcx, %rdx
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    movabsq $9223372036854775807, %rcx # imm = 0x7FFFFFFFFFFFFFFF
; CHECK-NEXT:    cmovaq %rcx, %rdx
; CHECK-NEXT:    movq $-1, %rcx
; CHECK-NEXT:    cmovaq %rcx, %rax
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpq %rsi, %rax
; CHECK-NEXT:    movl $0, %ecx
; CHECK-NEXT:    cmovpq %rcx, %rdx
; CHECK-NEXT:    movq %rdx, 8(%rbx)
; CHECK-NEXT:    movq %rax, (%rbx)
; CHECK-NEXT:    movq %r14, 56(%rbx)
; CHECK-NEXT:    movq %rbp, 48(%rbx)
; CHECK-NEXT:    movq %r13, 40(%rbx)
; CHECK-NEXT:    movq %r12, 32(%rbx)
; CHECK-NEXT:    movq %r15, 24(%rbx)
; CHECK-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; CHECK-NEXT:    movq %rax, 16(%rbx)
; CHECK-NEXT:    movq %rbx, %rax
; CHECK-NEXT:    addq $56, %rsp
; CHECK-NEXT:    popq %rbx
; CHECK-NEXT:    popq %r12
; CHECK-NEXT:    popq %r13
; CHECK-NEXT:    popq %r14
; CHECK-NEXT:    popq %r15
; CHECK-NEXT:    popq %rbp
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_signed_v4i128_v4f32:
; AVX512:       # %bb.0:
; AVX512-NEXT:    pushq %rbp
; AVX512-NEXT:    pushq %r15
; AVX512-NEXT:    pushq %r14
; AVX512-NEXT:    pushq %r13
; AVX512-NEXT:    pushq %r12
; AVX512-NEXT:    pushq %rbx
; AVX512-NEXT:    subq $56, %rsp
; AVX512-NEXT:    vmovaps %xmm0, (%rsp) # 16-byte Spill
; AVX512-NEXT:    movq %rdi, %rbx
; AVX512-NEXT:    vmovshdup {{.*#+}} xmm0 = xmm0[1,1,3,3]
; AVX512-NEXT:    vmovaps %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; AVX512-NEXT:    callq __fixsfti@PLT
; AVX512-NEXT:    movq %rdx, %r15
; AVX512-NEXT:    xorl %r14d, %r14d
; AVX512-NEXT:    vmovaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovbq %r14, %rax
; AVX512-NEXT:    movabsq $-9223372036854775808, %rcx # imm = 0x8000000000000000
; AVX512-NEXT:    cmovbq %rcx, %r15
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    movabsq $9223372036854775807, %rbp # imm = 0x7FFFFFFFFFFFFFFF
; AVX512-NEXT:    cmovaq %rbp, %r15
; AVX512-NEXT:    movq $-1, %rcx
; AVX512-NEXT:    cmovaq %rcx, %rax
; AVX512-NEXT:    vucomiss %xmm0, %xmm0
; AVX512-NEXT:    cmovpq %r14, %rax
; AVX512-NEXT:    movq %rax, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; AVX512-NEXT:    cmovpq %r14, %r15
; AVX512-NEXT:    vpermilpd $1, (%rsp), %xmm0 # 16-byte Folded Reload
; AVX512-NEXT:    # xmm0 = mem[1,0]
; AVX512-NEXT:    vmovapd %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; AVX512-NEXT:    callq __fixsfti@PLT
; AVX512-NEXT:    movq %rax, %r12
; AVX512-NEXT:    movq %rdx, %r13
; AVX512-NEXT:    vmovaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovbq %r14, %r12
; AVX512-NEXT:    movabsq $-9223372036854775808, %rax # imm = 0x8000000000000000
; AVX512-NEXT:    cmovbq %rax, %r13
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovaq %rbp, %r13
; AVX512-NEXT:    movq $-1, %rax
; AVX512-NEXT:    cmovaq %rax, %r12
; AVX512-NEXT:    vucomiss %xmm0, %xmm0
; AVX512-NEXT:    cmovpq %r14, %r12
; AVX512-NEXT:    cmovpq %r14, %r13
; AVX512-NEXT:    vpermilps $255, (%rsp), %xmm0 # 16-byte Folded Reload
; AVX512-NEXT:    # xmm0 = mem[3,3,3,3]
; AVX512-NEXT:    vmovaps %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; AVX512-NEXT:    callq __fixsfti@PLT
; AVX512-NEXT:    movq %rax, %rbp
; AVX512-NEXT:    movq %rdx, %r14
; AVX512-NEXT:    vmovaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    movl $0, %eax
; AVX512-NEXT:    cmovbq %rax, %rbp
; AVX512-NEXT:    movabsq $-9223372036854775808, %rcx # imm = 0x8000000000000000
; AVX512-NEXT:    cmovbq %rcx, %r14
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    movabsq $9223372036854775807, %rcx # imm = 0x7FFFFFFFFFFFFFFF
; AVX512-NEXT:    cmovaq %rcx, %r14
; AVX512-NEXT:    movq $-1, %rcx
; AVX512-NEXT:    cmovaq %rcx, %rbp
; AVX512-NEXT:    vucomiss %xmm0, %xmm0
; AVX512-NEXT:    cmovpq %rax, %rbp
; AVX512-NEXT:    cmovpq %rax, %r14
; AVX512-NEXT:    vmovaps (%rsp), %xmm0 # 16-byte Reload
; AVX512-NEXT:    callq __fixsfti@PLT
; AVX512-NEXT:    vmovaps (%rsp), %xmm0 # 16-byte Reload
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    movl $0, %esi
; AVX512-NEXT:    cmovbq %rsi, %rax
; AVX512-NEXT:    movabsq $-9223372036854775808, %rcx # imm = 0x8000000000000000
; AVX512-NEXT:    cmovbq %rcx, %rdx
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    movabsq $9223372036854775807, %rcx # imm = 0x7FFFFFFFFFFFFFFF
; AVX512-NEXT:    cmovaq %rcx, %rdx
; AVX512-NEXT:    movq $-1, %rcx
; AVX512-NEXT:    cmovaq %rcx, %rax
; AVX512-NEXT:    vucomiss %xmm0, %xmm0
; AVX512-NEXT:    cmovpq %rsi, %rax
; AVX512-NEXT:    movl $0, %ecx
; AVX512-NEXT:    cmovpq %rcx, %rdx
; AVX512-NEXT:    movq %rdx, 8(%rbx)
; AVX512-NEXT:    movq %rax, (%rbx)
; AVX512-NEXT:    movq %r14, 56(%rbx)
; AVX512-NEXT:    movq %rbp, 48(%rbx)
; AVX512-NEXT:    movq %r13, 40(%rbx)
; AVX512-NEXT:    movq %r12, 32(%rbx)
; AVX512-NEXT:    movq %r15, 24(%rbx)
; AVX512-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; AVX512-NEXT:    movq %rax, 16(%rbx)
; AVX512-NEXT:    movq %rbx, %rax
; AVX512-NEXT:    addq $56, %rsp
; AVX512-NEXT:    popq %rbx
; AVX512-NEXT:    popq %r12
; AVX512-NEXT:    popq %r13
; AVX512-NEXT:    popq %r14
; AVX512-NEXT:    popq %r15
; AVX512-NEXT:    popq %rbp
; AVX512-NEXT:    retq
  %x = call <4 x i128> @llvm.fptosi.sat.v4i128.v4f32(<4 x float> %f)
  ret <4 x i128> %x
}

;
; 64-bit float to signed integer
;

declare <2 x i1> @llvm.fptosi.sat.v2i1.v2f64(<2 x double>)
declare <2 x i8> @llvm.fptosi.sat.v2i8.v2f64(<2 x double>)
declare <2 x i16> @llvm.fptosi.sat.v2i16.v2f64(<2 x double>)
declare <2 x i32> @llvm.fptosi.sat.v2i32.v2f64(<2 x double>)
declare <2 x i64> @llvm.fptosi.sat.v2i64.v2f64(<2 x double>)
declare <2 x i128> @llvm.fptosi.sat.v2i128.v2f64(<2 x double>)

define <2 x i1> @test_signed_v2i1_v2f64(<2 x double> %f) nounwind {
; CHECK-LABEL: test_signed_v2i1_v2f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    movapd %xmm0, %xmm1
; CHECK-NEXT:    maxsd %xmm2, %xmm1
; CHECK-NEXT:    xorpd %xmm3, %xmm3
; CHECK-NEXT:    minsd %xmm3, %xmm1
; CHECK-NEXT:    cvttsd2si %xmm1, %rax
; CHECK-NEXT:    xorl %ecx, %ecx
; CHECK-NEXT:    ucomisd %xmm0, %xmm0
; CHECK-NEXT:    cmovpq %rcx, %rax
; CHECK-NEXT:    movq %rax, %xmm1
; CHECK-NEXT:    unpckhpd {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    ucomisd %xmm0, %xmm0
; CHECK-NEXT:    maxsd %xmm2, %xmm0
; CHECK-NEXT:    minsd %xmm3, %xmm0
; CHECK-NEXT:    cvttsd2si %xmm0, %rax
; CHECK-NEXT:    cmovpq %rcx, %rax
; CHECK-NEXT:    movq %rax, %xmm0
; CHECK-NEXT:    punpcklqdq {{.*#+}} xmm1 = xmm1[0],xmm0[0]
; CHECK-NEXT:    movdqa %xmm1, %xmm0
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_signed_v2i1_v2f64:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vmovddup {{.*#+}} xmm1 = [-1.0E+0,-1.0E+0]
; AVX512-NEXT:    # xmm1 = mem[0,0]
; AVX512-NEXT:    vmaxpd %xmm0, %xmm1, %xmm0
; AVX512-NEXT:    vxorpd %xmm1, %xmm1, %xmm1
; AVX512-NEXT:    vminpd %xmm0, %xmm1, %xmm0
; AVX512-NEXT:    vcvttpd2dq %xmm0, %xmm0
; AVX512-NEXT:    vpslld $31, %xmm0, %xmm0
; AVX512-NEXT:    vpmovd2m %xmm0, %k0
; AVX512-NEXT:    vpmovm2q %k0, %xmm0
; AVX512-NEXT:    retq
  %x = call <2 x i1> @llvm.fptosi.sat.v2i1.v2f64(<2 x double> %f)
  ret <2 x i1> %x
}

define <2 x i8> @test_signed_v2i8_v2f64(<2 x double> %f) nounwind {
; CHECK-LABEL: test_signed_v2i8_v2f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    movapd %xmm0, %xmm1
; CHECK-NEXT:    maxsd %xmm2, %xmm1
; CHECK-NEXT:    movsd {{.*#+}} xmm3 = mem[0],zero
; CHECK-NEXT:    minsd %xmm3, %xmm1
; CHECK-NEXT:    cvttsd2si %xmm1, %eax
; CHECK-NEXT:    xorl %ecx, %ecx
; CHECK-NEXT:    ucomisd %xmm0, %xmm0
; CHECK-NEXT:    cmovpl %ecx, %eax
; CHECK-NEXT:    movd %eax, %xmm1
; CHECK-NEXT:    unpckhpd {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    ucomisd %xmm0, %xmm0
; CHECK-NEXT:    maxsd %xmm2, %xmm0
; CHECK-NEXT:    minsd %xmm3, %xmm0
; CHECK-NEXT:    cvttsd2si %xmm0, %eax
; CHECK-NEXT:    cmovpl %ecx, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    punpckldq {{.*#+}} xmm1 = xmm1[0],xmm0[0],xmm1[1],xmm0[1]
; CHECK-NEXT:    packuswb %xmm1, %xmm1
; CHECK-NEXT:    packuswb %xmm1, %xmm1
; CHECK-NEXT:    movdqa %xmm1, %xmm0
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_signed_v2i8_v2f64:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vmovapd %xmm0, %xmm0
; AVX512-NEXT:    vmaxpd {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to4}, %ymm0, %ymm1
; AVX512-NEXT:    vminpd {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to4}, %ymm1, %ymm1
; AVX512-NEXT:    vcmpunordpd %ymm0, %ymm0, %k0
; AVX512-NEXT:    knotw %k0, %k1
; AVX512-NEXT:    vcvttpd2dq %ymm1, %xmm0 {%k1} {z}
; AVX512-NEXT:    vpmovdb %xmm0, %xmm0
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %x = call <2 x i8> @llvm.fptosi.sat.v2i8.v2f64(<2 x double> %f)
  ret <2 x i8> %x
}

define <2 x i16> @test_signed_v2i16_v2f64(<2 x double> %f) nounwind {
; CHECK-LABEL: test_signed_v2i16_v2f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    movapd %xmm0, %xmm2
; CHECK-NEXT:    maxsd %xmm1, %xmm2
; CHECK-NEXT:    movsd {{.*#+}} xmm3 = mem[0],zero
; CHECK-NEXT:    minsd %xmm3, %xmm2
; CHECK-NEXT:    cvttsd2si %xmm2, %eax
; CHECK-NEXT:    xorl %ecx, %ecx
; CHECK-NEXT:    ucomisd %xmm0, %xmm0
; CHECK-NEXT:    cmovpl %ecx, %eax
; CHECK-NEXT:    movd %eax, %xmm2
; CHECK-NEXT:    unpckhpd {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    ucomisd %xmm0, %xmm0
; CHECK-NEXT:    maxsd %xmm1, %xmm0
; CHECK-NEXT:    minsd %xmm3, %xmm0
; CHECK-NEXT:    cvttsd2si %xmm0, %eax
; CHECK-NEXT:    cmovpl %ecx, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    punpckldq {{.*#+}} xmm2 = xmm2[0],xmm0[0],xmm2[1],xmm0[1]
; CHECK-NEXT:    pshuflw {{.*#+}} xmm0 = xmm2[0,2,2,3,4,5,6,7]
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_signed_v2i16_v2f64:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vmovapd %xmm0, %xmm0
; AVX512-NEXT:    vmaxpd {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to4}, %ymm0, %ymm1
; AVX512-NEXT:    vminpd {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to4}, %ymm1, %ymm1
; AVX512-NEXT:    vcmpunordpd %ymm0, %ymm0, %k0
; AVX512-NEXT:    knotw %k0, %k1
; AVX512-NEXT:    vcvttpd2dq %ymm1, %xmm0 {%k1} {z}
; AVX512-NEXT:    vpackusdw %xmm0, %xmm0, %xmm0
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %x = call <2 x i16> @llvm.fptosi.sat.v2i16.v2f64(<2 x double> %f)
  ret <2 x i16> %x
}

define <2 x i32> @test_signed_v2i32_v2f64(<2 x double> %f) nounwind {
; CHECK-LABEL: test_signed_v2i32_v2f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    movapd %xmm0, %xmm1
; CHECK-NEXT:    maxsd %xmm2, %xmm1
; CHECK-NEXT:    movsd {{.*#+}} xmm3 = mem[0],zero
; CHECK-NEXT:    minsd %xmm3, %xmm1
; CHECK-NEXT:    cvttsd2si %xmm1, %eax
; CHECK-NEXT:    xorl %ecx, %ecx
; CHECK-NEXT:    ucomisd %xmm0, %xmm0
; CHECK-NEXT:    cmovpl %ecx, %eax
; CHECK-NEXT:    movd %eax, %xmm1
; CHECK-NEXT:    unpckhpd {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    ucomisd %xmm0, %xmm0
; CHECK-NEXT:    maxsd %xmm2, %xmm0
; CHECK-NEXT:    minsd %xmm3, %xmm0
; CHECK-NEXT:    cvttsd2si %xmm0, %eax
; CHECK-NEXT:    cmovpl %ecx, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    punpckldq {{.*#+}} xmm1 = xmm1[0],xmm0[0],xmm1[1],xmm0[1]
; CHECK-NEXT:    movdqa %xmm1, %xmm0
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_signed_v2i32_v2f64:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vmovapd %xmm0, %xmm0
; AVX512-NEXT:    vmaxpd {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to4}, %ymm0, %ymm1
; AVX512-NEXT:    vminpd {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to4}, %ymm1, %ymm1
; AVX512-NEXT:    vcmpunordpd %ymm0, %ymm0, %k0
; AVX512-NEXT:    knotw %k0, %k1
; AVX512-NEXT:    vcvttpd2dq %ymm1, %xmm0 {%k1} {z}
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %x = call <2 x i32> @llvm.fptosi.sat.v2i32.v2f64(<2 x double> %f)
  ret <2 x i32> %x
}

define <2 x i64> @test_signed_v2i64_v2f64(<2 x double> %f) nounwind {
; CHECK-LABEL: test_signed_v2i64_v2f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    cvttsd2si %xmm0, %rax
; CHECK-NEXT:    movsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    ucomisd %xmm2, %xmm0
; CHECK-NEXT:    movabsq $9223372036854775807, %rcx # imm = 0x7FFFFFFFFFFFFFFF
; CHECK-NEXT:    cmovaq %rcx, %rax
; CHECK-NEXT:    xorl %edx, %edx
; CHECK-NEXT:    ucomisd %xmm0, %xmm0
; CHECK-NEXT:    cmovpq %rdx, %rax
; CHECK-NEXT:    movq %rax, %xmm1
; CHECK-NEXT:    unpckhpd {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    cvttsd2si %xmm0, %rax
; CHECK-NEXT:    ucomisd %xmm2, %xmm0
; CHECK-NEXT:    cmovaq %rcx, %rax
; CHECK-NEXT:    ucomisd %xmm0, %xmm0
; CHECK-NEXT:    cmovpq %rdx, %rax
; CHECK-NEXT:    movq %rax, %xmm0
; CHECK-NEXT:    punpcklqdq {{.*#+}} xmm1 = xmm1[0],xmm0[0]
; CHECK-NEXT:    movdqa %xmm1, %xmm0
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_signed_v2i64_v2f64:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vcmpgtpd {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to2}, %xmm0, %k1
; AVX512-NEXT:    vcvttpd2qq %xmm0, %xmm1
; AVX512-NEXT:    vpbroadcastq {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1 {%k1}
; AVX512-NEXT:    vcmpunordpd %xmm0, %xmm0, %k0
; AVX512-NEXT:    knotw %k0, %k1
; AVX512-NEXT:    vmovdqa64 %xmm1, %xmm0 {%k1} {z}
; AVX512-NEXT:    retq
  %x = call <2 x i64> @llvm.fptosi.sat.v2i64.v2f64(<2 x double> %f)
  ret <2 x i64> %x
}

define <2 x i128> @test_signed_v2i128_v2f64(<2 x double> %f) nounwind {
; CHECK-LABEL: test_signed_v2i128_v2f64:
; CHECK:       # %bb.0:
; CHECK-NEXT:    pushq %rbp
; CHECK-NEXT:    pushq %r15
; CHECK-NEXT:    pushq %r14
; CHECK-NEXT:    pushq %r13
; CHECK-NEXT:    pushq %r12
; CHECK-NEXT:    pushq %rbx
; CHECK-NEXT:    subq $40, %rsp
; CHECK-NEXT:    movaps %xmm0, (%rsp) # 16-byte Spill
; CHECK-NEXT:    movq %rdi, %rbx
; CHECK-NEXT:    movhlps {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    movaps %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    callq __fixdfti@PLT
; CHECK-NEXT:    movq %rax, %r14
; CHECK-NEXT:    movq %rdx, %r15
; CHECK-NEXT:    xorl %r12d, %r12d
; CHECK-NEXT:    movapd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    ucomisd {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %r12, %r14
; CHECK-NEXT:    movabsq $-9223372036854775808, %rax # imm = 0x8000000000000000
; CHECK-NEXT:    cmovbq %rax, %r15
; CHECK-NEXT:    ucomisd {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    movabsq $9223372036854775807, %rbp # imm = 0x7FFFFFFFFFFFFFFF
; CHECK-NEXT:    cmovaq %rbp, %r15
; CHECK-NEXT:    movq $-1, %r13
; CHECK-NEXT:    cmovaq %r13, %r14
; CHECK-NEXT:    ucomisd %xmm0, %xmm0
; CHECK-NEXT:    cmovpq %r12, %r14
; CHECK-NEXT:    cmovpq %r12, %r15
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    callq __fixdfti@PLT
; CHECK-NEXT:    movapd (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    ucomisd {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %r12, %rax
; CHECK-NEXT:    movabsq $-9223372036854775808, %rcx # imm = 0x8000000000000000
; CHECK-NEXT:    cmovbq %rcx, %rdx
; CHECK-NEXT:    ucomisd {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %rbp, %rdx
; CHECK-NEXT:    cmovaq %r13, %rax
; CHECK-NEXT:    ucomisd %xmm0, %xmm0
; CHECK-NEXT:    cmovpq %r12, %rax
; CHECK-NEXT:    cmovpq %r12, %rdx
; CHECK-NEXT:    movq %rdx, 8(%rbx)
; CHECK-NEXT:    movq %rax, (%rbx)
; CHECK-NEXT:    movq %r15, 24(%rbx)
; CHECK-NEXT:    movq %r14, 16(%rbx)
; CHECK-NEXT:    movq %rbx, %rax
; CHECK-NEXT:    addq $40, %rsp
; CHECK-NEXT:    popq %rbx
; CHECK-NEXT:    popq %r12
; CHECK-NEXT:    popq %r13
; CHECK-NEXT:    popq %r14
; CHECK-NEXT:    popq %r15
; CHECK-NEXT:    popq %rbp
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_signed_v2i128_v2f64:
; AVX512:       # %bb.0:
; AVX512-NEXT:    pushq %rbp
; AVX512-NEXT:    pushq %r15
; AVX512-NEXT:    pushq %r14
; AVX512-NEXT:    pushq %r13
; AVX512-NEXT:    pushq %r12
; AVX512-NEXT:    pushq %rbx
; AVX512-NEXT:    subq $40, %rsp
; AVX512-NEXT:    vmovapd %xmm0, (%rsp) # 16-byte Spill
; AVX512-NEXT:    movq %rdi, %rbx
; AVX512-NEXT:    vshufpd {{.*#+}} xmm0 = xmm0[1,0]
; AVX512-NEXT:    vmovapd %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; AVX512-NEXT:    callq __fixdfti@PLT
; AVX512-NEXT:    movq %rax, %r14
; AVX512-NEXT:    movq %rdx, %r15
; AVX512-NEXT:    xorl %r12d, %r12d
; AVX512-NEXT:    vmovapd {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Reload
; AVX512-NEXT:    vucomisd {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1
; AVX512-NEXT:    cmovbq %r12, %r14
; AVX512-NEXT:    movabsq $-9223372036854775808, %rax # imm = 0x8000000000000000
; AVX512-NEXT:    cmovbq %rax, %r15
; AVX512-NEXT:    vucomisd {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1
; AVX512-NEXT:    movabsq $9223372036854775807, %rbp # imm = 0x7FFFFFFFFFFFFFFF
; AVX512-NEXT:    cmovaq %rbp, %r15
; AVX512-NEXT:    movq $-1, %r13
; AVX512-NEXT:    cmovaq %r13, %r14
; AVX512-NEXT:    vucomisd %xmm1, %xmm1
; AVX512-NEXT:    cmovpq %r12, %r14
; AVX512-NEXT:    cmovpq %r12, %r15
; AVX512-NEXT:    vmovaps (%rsp), %xmm0 # 16-byte Reload
; AVX512-NEXT:    callq __fixdfti@PLT
; AVX512-NEXT:    vmovapd (%rsp), %xmm0 # 16-byte Reload
; AVX512-NEXT:    vucomisd {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovbq %r12, %rax
; AVX512-NEXT:    movabsq $-9223372036854775808, %rcx # imm = 0x8000000000000000
; AVX512-NEXT:    cmovbq %rcx, %rdx
; AVX512-NEXT:    vucomisd {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovaq %rbp, %rdx
; AVX512-NEXT:    cmovaq %r13, %rax
; AVX512-NEXT:    vucomisd %xmm0, %xmm0
; AVX512-NEXT:    cmovpq %r12, %rax
; AVX512-NEXT:    cmovpq %r12, %rdx
; AVX512-NEXT:    movq %rdx, 8(%rbx)
; AVX512-NEXT:    movq %rax, (%rbx)
; AVX512-NEXT:    movq %r15, 24(%rbx)
; AVX512-NEXT:    movq %r14, 16(%rbx)
; AVX512-NEXT:    movq %rbx, %rax
; AVX512-NEXT:    addq $40, %rsp
; AVX512-NEXT:    popq %rbx
; AVX512-NEXT:    popq %r12
; AVX512-NEXT:    popq %r13
; AVX512-NEXT:    popq %r14
; AVX512-NEXT:    popq %r15
; AVX512-NEXT:    popq %rbp
; AVX512-NEXT:    retq
  %x = call <2 x i128> @llvm.fptosi.sat.v2i128.v2f64(<2 x double> %f)
  ret <2 x i128> %x
}

;
; 16-bit float to signed integer
;

declare <8 x i1> @llvm.fptosi.sat.v8i1.v8f16(<8 x half>)
declare <8 x i8> @llvm.fptosi.sat.v8i8.v8f16(<8 x half>)
declare <8 x i16> @llvm.fptosi.sat.v8i16.v8f16(<8 x half>)
declare <8 x i32> @llvm.fptosi.sat.v8i32.v8f16(<8 x half>)
declare <8 x i64> @llvm.fptosi.sat.v8i64.v8f16(<8 x half>)
declare <8 x i128> @llvm.fptosi.sat.v8i128.v8f16(<8 x half>)

define <8 x i1> @test_signed_v8i1_v8f16(<8 x half> %f) nounwind {
; CHECK-LABEL: test_signed_v8i1_v8f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    pushq %rbp
; CHECK-NEXT:    pushq %rbx
; CHECK-NEXT:    subq $72, %rsp
; CHECK-NEXT:    movdqa %xmm0, (%rsp) # 16-byte Spill
; CHECK-NEXT:    psrldq {{.*#+}} xmm0 = xmm0[14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    movl $65535, %ebp # imm = 0xFFFF
; CHECK-NEXT:    cmovbl %ebp, %eax
; CHECK-NEXT:    xorl %ebx, %ebx
; CHECK-NEXT:    xorps %xmm1, %xmm1
; CHECK-NEXT:    ucomiss %xmm1, %xmm0
; CHECK-NEXT:    cmoval %ebx, %eax
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpl %ebx, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[3,3,3,3]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebp, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebx, %eax
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpl %ebx, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    punpcklwd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1],xmm0[2],mem[2],xmm0[3],mem[3]
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrldq {{.*#+}} xmm0 = xmm0[10,11,12,13,14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebp, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebx, %eax
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpl %ebx, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    movhlps {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebp, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebx, %eax
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpl %ebx, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    punpcklwd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1],xmm0[2],mem[2],xmm0[3],mem[3]
; CHECK-NEXT:    punpckldq {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1]
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrlq $48, %xmm0
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebp, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebx, %eax
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpl %ebx, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[1,1,1,1]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebp, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebx, %eax
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpl %ebx, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    punpcklwd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1],xmm0[2],mem[2],xmm0[3],mem[3]
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebp, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebx, %eax
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpl %ebx, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrld $16, %xmm0
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebp, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebx, %eax
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpl %ebx, %eax
; CHECK-NEXT:    movd %eax, %xmm1
; CHECK-NEXT:    movdqa {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    punpcklwd {{.*#+}} xmm0 = xmm0[0],xmm1[0],xmm0[1],xmm1[1],xmm0[2],xmm1[2],xmm0[3],xmm1[3]
; CHECK-NEXT:    punpckldq {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1]
; CHECK-NEXT:    punpcklqdq {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0]
; CHECK-NEXT:    addq $72, %rsp
; CHECK-NEXT:    popq %rbx
; CHECK-NEXT:    popq %rbp
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_signed_v8i1_v8f16:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vpbroadcastw {{.*#+}} xmm1 = [-1.0E+0,-1.0E+0,-1.0E+0,-1.0E+0,-1.0E+0,-1.0E+0,-1.0E+0,-1.0E+0]
; AVX512-NEXT:    vmaxph %xmm0, %xmm1, %xmm0
; AVX512-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; AVX512-NEXT:    vminph %xmm0, %xmm1, %xmm0
; AVX512-NEXT:    vcvttph2dq %xmm0, %ymm0
; AVX512-NEXT:    vpslld $31, %ymm0, %ymm0
; AVX512-NEXT:    vpmovd2m %ymm0, %k0
; AVX512-NEXT:    vpmovm2w %k0, %xmm0
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %x = call <8 x i1> @llvm.fptosi.sat.v8i1.v8f16(<8 x half> %f)
  ret <8 x i1> %x
}

define <8 x i8> @test_signed_v8i8_v8f16(<8 x half> %f) nounwind {
; CHECK-LABEL: test_signed_v8i8_v8f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    subq $72, %rsp
; CHECK-NEXT:    movdqa %xmm0, (%rsp) # 16-byte Spill
; CHECK-NEXT:    psrldq {{.*#+}} xmm0 = xmm0[14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[3,3,3,3]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    unpcklps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1]
; CHECK-NEXT:    movaps %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrldq {{.*#+}} xmm0 = xmm0[10,11,12,13,14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    movhlps {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    unpcklps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1]
; CHECK-NEXT:    unpcklpd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0]
; CHECK-NEXT:    movaps %xmm0, %xmm1
; CHECK-NEXT:    cmpunordps %xmm0, %xmm1
; CHECK-NEXT:    maxps {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    minps {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cvttps2dq %xmm0, %xmm0
; CHECK-NEXT:    andnps %xmm0, %xmm1
; CHECK-NEXT:    pslld $16, %xmm1
; CHECK-NEXT:    psrad $16, %xmm1
; CHECK-NEXT:    movdqa %xmm1, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrlq $48, %xmm0
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[1,1,1,1]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    unpcklps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1]
; CHECK-NEXT:    movaps %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movaps %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrld $16, %xmm0
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movdqa {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Reload
; CHECK-NEXT:    punpckldq {{.*#+}} xmm1 = xmm1[0],xmm0[0],xmm1[1],xmm0[1]
; CHECK-NEXT:    punpcklqdq {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm1 = xmm1[0],mem[0]
; CHECK-NEXT:    movdqa %xmm1, %xmm0
; CHECK-NEXT:    cmpunordps %xmm1, %xmm0
; CHECK-NEXT:    maxps {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1
; CHECK-NEXT:    minps {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1
; CHECK-NEXT:    cvttps2dq %xmm1, %xmm1
; CHECK-NEXT:    andnps %xmm1, %xmm0
; CHECK-NEXT:    pslld $16, %xmm0
; CHECK-NEXT:    psrad $16, %xmm0
; CHECK-NEXT:    packssdw {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    packuswb %xmm0, %xmm0
; CHECK-NEXT:    addq $72, %rsp
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_signed_v8i8_v8f16:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vpbroadcastw {{.*#+}} xmm1 = [-1.28E+2,-1.28E+2,-1.28E+2,-1.28E+2,-1.28E+2,-1.28E+2,-1.28E+2,-1.28E+2]
; AVX512-NEXT:    vmaxph %xmm0, %xmm1, %xmm0
; AVX512-NEXT:    vpbroadcastw {{.*#+}} xmm1 = [1.27E+2,1.27E+2,1.27E+2,1.27E+2,1.27E+2,1.27E+2,1.27E+2,1.27E+2]
; AVX512-NEXT:    vminph %xmm0, %xmm1, %xmm0
; AVX512-NEXT:    vcvttph2dq %xmm0, %ymm0
; AVX512-NEXT:    vpmovdw %ymm0, %xmm0
; AVX512-NEXT:    vpacksswb %xmm0, %xmm0, %xmm0
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %x = call <8 x i8> @llvm.fptosi.sat.v8i8.v8f16(<8 x half> %f)
  ret <8 x i8> %x
}

define <8 x i16> @test_signed_v8i16_v8f16(<8 x half> %f) nounwind {
; CHECK-LABEL: test_signed_v8i16_v8f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    pushq %rbp
; CHECK-NEXT:    pushq %r14
; CHECK-NEXT:    pushq %rbx
; CHECK-NEXT:    subq $64, %rsp
; CHECK-NEXT:    movdqa %xmm0, (%rsp) # 16-byte Spill
; CHECK-NEXT:    psrldq {{.*#+}} xmm0 = xmm0[14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    movl $32768, %ebx # imm = 0x8000
; CHECK-NEXT:    cmovbl %ebx, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    movl $32767, %ebp # imm = 0x7FFF
; CHECK-NEXT:    cmoval %ebp, %eax
; CHECK-NEXT:    xorl %r14d, %r14d
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpl %r14d, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[3,3,3,3]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebx, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebp, %eax
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpl %r14d, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    punpcklwd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1],xmm0[2],mem[2],xmm0[3],mem[3]
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrldq {{.*#+}} xmm0 = xmm0[10,11,12,13,14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebx, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebp, %eax
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpl %r14d, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    movhlps {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebx, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebp, %eax
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpl %r14d, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    punpcklwd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1],xmm0[2],mem[2],xmm0[3],mem[3]
; CHECK-NEXT:    punpckldq {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1]
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrlq $48, %xmm0
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebx, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebp, %eax
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpl %r14d, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[1,1,1,1]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebx, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebp, %eax
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpl %r14d, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    punpcklwd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1],xmm0[2],mem[2],xmm0[3],mem[3]
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebx, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebp, %eax
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpl %r14d, %eax
; CHECK-NEXT:    movd %eax, %xmm0
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrld $16, %xmm0
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbl %ebx, %eax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmoval %ebp, %eax
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpl %r14d, %eax
; CHECK-NEXT:    movd %eax, %xmm1
; CHECK-NEXT:    movdqa {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    punpcklwd {{.*#+}} xmm0 = xmm0[0],xmm1[0],xmm0[1],xmm1[1],xmm0[2],xmm1[2],xmm0[3],xmm1[3]
; CHECK-NEXT:    punpckldq {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1]
; CHECK-NEXT:    punpcklqdq {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0]
; CHECK-NEXT:    addq $64, %rsp
; CHECK-NEXT:    popq %rbx
; CHECK-NEXT:    popq %r14
; CHECK-NEXT:    popq %rbp
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_signed_v8i16_v8f16:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vcmpngeph {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to8}, %xmm0, %k1
; AVX512-NEXT:    vcvttph2dq %xmm0, %ymm1
; AVX512-NEXT:    vpmovdw %ymm1, %xmm1
; AVX512-NEXT:    vmovdqu16 {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1 {%k1}
; AVX512-NEXT:    vcmpgtph {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to8}, %xmm0, %k1
; AVX512-NEXT:    vmovdqu16 {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1 {%k1}
; AVX512-NEXT:    vmovdqa %xmm1, %xmm0
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %x = call <8 x i16> @llvm.fptosi.sat.v8i16.v8f16(<8 x half> %f)
  ret <8 x i16> %x
}

define <8 x i32> @test_signed_v8i32_v8f16(<8 x half> %f) nounwind {
; CHECK-LABEL: test_signed_v8i32_v8f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    subq $72, %rsp
; CHECK-NEXT:    movdqa %xmm0, (%rsp) # 16-byte Spill
; CHECK-NEXT:    psrlq $48, %xmm0
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[1,1,1,1]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movaps %xmm0, %xmm3
; CHECK-NEXT:    unpcklps {{[-0-9]+}}(%r{{[sb]}}p), %xmm3 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm3 = xmm3[0],mem[0],xmm3[1],mem[1]
; CHECK-NEXT:    movaps {{.*#+}} xmm0 = [2.14748352E+9,2.14748352E+9,2.14748352E+9,2.14748352E+9]
; CHECK-NEXT:    cmpltps %xmm3, %xmm0
; CHECK-NEXT:    cvttps2dq %xmm3, %xmm1
; CHECK-NEXT:    movaps %xmm0, %xmm2
; CHECK-NEXT:    andnps %xmm1, %xmm2
; CHECK-NEXT:    andps {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    orps %xmm2, %xmm0
; CHECK-NEXT:    cmpunordps %xmm3, %xmm3
; CHECK-NEXT:    andnps %xmm0, %xmm3
; CHECK-NEXT:    movaps %xmm3, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movaps %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrld $16, %xmm0
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movdqa {{[-0-9]+}}(%r{{[sb]}}p), %xmm3 # 16-byte Reload
; CHECK-NEXT:    punpckldq {{.*#+}} xmm3 = xmm3[0],xmm0[0],xmm3[1],xmm0[1]
; CHECK-NEXT:    movaps {{.*#+}} xmm0 = [2.14748352E+9,2.14748352E+9,2.14748352E+9,2.14748352E+9]
; CHECK-NEXT:    cmpltps %xmm3, %xmm0
; CHECK-NEXT:    cvttps2dq %xmm3, %xmm1
; CHECK-NEXT:    movaps %xmm0, %xmm2
; CHECK-NEXT:    andnps %xmm1, %xmm2
; CHECK-NEXT:    andps {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    orps %xmm2, %xmm0
; CHECK-NEXT:    cmpunordps %xmm3, %xmm3
; CHECK-NEXT:    andnps %xmm0, %xmm3
; CHECK-NEXT:    unpcklpd {{[-0-9]+}}(%r{{[sb]}}p), %xmm3 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm3 = xmm3[0],mem[0]
; CHECK-NEXT:    movaps %xmm3, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrldq {{.*#+}} xmm0 = xmm0[14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[3,3,3,3]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movaps %xmm0, %xmm3
; CHECK-NEXT:    unpcklps {{[-0-9]+}}(%r{{[sb]}}p), %xmm3 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm3 = xmm3[0],mem[0],xmm3[1],mem[1]
; CHECK-NEXT:    movaps {{.*#+}} xmm0 = [2.14748352E+9,2.14748352E+9,2.14748352E+9,2.14748352E+9]
; CHECK-NEXT:    cmpltps %xmm3, %xmm0
; CHECK-NEXT:    cvttps2dq %xmm3, %xmm1
; CHECK-NEXT:    movaps %xmm0, %xmm2
; CHECK-NEXT:    andnps %xmm1, %xmm2
; CHECK-NEXT:    andps {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    orps %xmm2, %xmm0
; CHECK-NEXT:    cmpunordps %xmm3, %xmm3
; CHECK-NEXT:    andnps %xmm0, %xmm3
; CHECK-NEXT:    movaps %xmm3, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrldq {{.*#+}} xmm0 = xmm0[10,11,12,13,14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    movhlps {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movaps %xmm0, %xmm1
; CHECK-NEXT:    unpcklps {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm1 = xmm1[0],mem[0],xmm1[1],mem[1]
; CHECK-NEXT:    movaps {{.*#+}} xmm3 = [2.14748352E+9,2.14748352E+9,2.14748352E+9,2.14748352E+9]
; CHECK-NEXT:    cmpltps %xmm1, %xmm3
; CHECK-NEXT:    cvttps2dq %xmm1, %xmm0
; CHECK-NEXT:    movaps %xmm3, %xmm2
; CHECK-NEXT:    andnps %xmm0, %xmm2
; CHECK-NEXT:    andps {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm3
; CHECK-NEXT:    orps %xmm2, %xmm3
; CHECK-NEXT:    cmpunordps %xmm1, %xmm1
; CHECK-NEXT:    andnps %xmm3, %xmm1
; CHECK-NEXT:    unpcklpd {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm1 = xmm1[0],mem[0]
; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    addq $72, %rsp
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_signed_v8i32_v8f16:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vcmpgtph {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to8}, %xmm0, %k1
; AVX512-NEXT:    vcvttph2dq %xmm0, %ymm1
; AVX512-NEXT:    vpbroadcastd {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %ymm1 {%k1}
; AVX512-NEXT:    vcmpunordph %xmm0, %xmm0, %k0
; AVX512-NEXT:    knotb %k0, %k1
; AVX512-NEXT:    vmovdqa32 %ymm1, %ymm0 {%k1} {z}
; AVX512-NEXT:    retq
  %x = call <8 x i32> @llvm.fptosi.sat.v8i32.v8f16(<8 x half> %f)
  ret <8 x i32> %x
}

define <8 x i64> @test_signed_v8i64_v8f16(<8 x half> %f) nounwind {
; CHECK-LABEL: test_signed_v8i64_v8f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    pushq %r15
; CHECK-NEXT:    pushq %r14
; CHECK-NEXT:    pushq %rbx
; CHECK-NEXT:    subq $80, %rsp
; CHECK-NEXT:    movaps %xmm0, (%rsp) # 16-byte Spill
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %rax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    movabsq $-9223372036854775808, %rbx # imm = 0x8000000000000000
; CHECK-NEXT:    cmovbq %rbx, %rax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    movabsq $9223372036854775807, %r14 # imm = 0x7FFFFFFFFFFFFFFF
; CHECK-NEXT:    cmovaq %r14, %rax
; CHECK-NEXT:    xorl %r15d, %r15d
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpq %r15, %rax
; CHECK-NEXT:    movq %rax, %xmm0
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrld $16, %xmm0
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %rax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %rbx, %rax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %r14, %rax
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpq %r15, %rax
; CHECK-NEXT:    movq %rax, %xmm0
; CHECK-NEXT:    movdqa {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Reload
; CHECK-NEXT:    punpcklqdq {{.*#+}} xmm1 = xmm1[0],xmm0[0]
; CHECK-NEXT:    movdqa %xmm1, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrlq $48, %xmm0
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %rax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %rbx, %rax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %r14, %rax
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpq %r15, %rax
; CHECK-NEXT:    movq %rax, %xmm0
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[1,1,1,1]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %rax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %rbx, %rax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %r14, %rax
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpq %r15, %rax
; CHECK-NEXT:    movq %rax, %xmm0
; CHECK-NEXT:    punpcklqdq {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0]
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrldq {{.*#+}} xmm0 = xmm0[10,11,12,13,14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %rax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %rbx, %rax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %r14, %rax
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpq %r15, %rax
; CHECK-NEXT:    movq %rax, %xmm0
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    movhlps {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %rax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %rbx, %rax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %r14, %rax
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpq %r15, %rax
; CHECK-NEXT:    movq %rax, %xmm0
; CHECK-NEXT:    punpcklqdq {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0]
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movdqa (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrldq {{.*#+}} xmm0 = xmm0[14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %rax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %rbx, %rax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %r14, %rax
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpq %r15, %rax
; CHECK-NEXT:    movq %rax, %xmm0
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movaps (%rsp), %xmm0 # 16-byte Reload
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[3,3,3,3]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    cvttss2si %xmm0, %rax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %rbx, %rax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %r14, %rax
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpq %r15, %rax
; CHECK-NEXT:    movq %rax, %xmm3
; CHECK-NEXT:    punpcklqdq {{[-0-9]+}}(%r{{[sb]}}p), %xmm3 # 16-byte Folded Reload
; CHECK-NEXT:    # xmm3 = xmm3[0],mem[0]
; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Reload
; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm2 # 16-byte Reload
; CHECK-NEXT:    addq $80, %rsp
; CHECK-NEXT:    popq %rbx
; CHECK-NEXT:    popq %r14
; CHECK-NEXT:    popq %r15
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_signed_v8i64_v8f16:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vcmpgtph {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to8}, %xmm0, %k1
; AVX512-NEXT:    vcvttph2qq %xmm0, %zmm1
; AVX512-NEXT:    vpbroadcastq {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %zmm1 {%k1}
; AVX512-NEXT:    vcmpunordph %xmm0, %xmm0, %k0
; AVX512-NEXT:    knotb %k0, %k1
; AVX512-NEXT:    vmovdqa64 %zmm1, %zmm0 {%k1} {z}
; AVX512-NEXT:    retq
  %x = call <8 x i64> @llvm.fptosi.sat.v8i64.v8f16(<8 x half> %f)
  ret <8 x i64> %x
}

define <8 x i128> @test_signed_v8i128_v8f16(<8 x half> %f) nounwind {
; CHECK-LABEL: test_signed_v8i128_v8f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    pushq %rbp
; CHECK-NEXT:    pushq %r15
; CHECK-NEXT:    pushq %r14
; CHECK-NEXT:    pushq %r13
; CHECK-NEXT:    pushq %r12
; CHECK-NEXT:    pushq %rbx
; CHECK-NEXT:    subq $104, %rsp
; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    movq %rdi, %rbx
; CHECK-NEXT:    psrld $16, %xmm0
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movd %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Folded Spill
; CHECK-NEXT:    callq __fixsfti@PLT
; CHECK-NEXT:    xorl %r12d, %r12d
; CHECK-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %r12, %rax
; CHECK-NEXT:    movabsq $-9223372036854775808, %rcx # imm = 0x8000000000000000
; CHECK-NEXT:    cmovbq %rcx, %rdx
; CHECK-NEXT:    movq %rcx, %r14
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    movabsq $9223372036854775807, %rcx # imm = 0x7FFFFFFFFFFFFFFF
; CHECK-NEXT:    cmovaq %rcx, %rdx
; CHECK-NEXT:    movq %rcx, %r15
; CHECK-NEXT:    movq $-1, %rcx
; CHECK-NEXT:    cmovaq %rcx, %rax
; CHECK-NEXT:    movq $-1, %r13
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpq %r12, %rax
; CHECK-NEXT:    movq %rax, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; CHECK-NEXT:    cmovpq %r12, %rdx
; CHECK-NEXT:    movq %rdx, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[1,1,1,1]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; CHECK-NEXT:    callq __fixsfti@PLT
; CHECK-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %r12, %rax
; CHECK-NEXT:    cmovbq %r14, %rdx
; CHECK-NEXT:    movq %r14, %rbp
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %r15, %rdx
; CHECK-NEXT:    cmovaq %r13, %rax
; CHECK-NEXT:    movq $-1, %r14
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpq %r12, %rax
; CHECK-NEXT:    movq %rax, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; CHECK-NEXT:    cmovpq %r12, %rdx
; CHECK-NEXT:    movq %rdx, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; CHECK-NEXT:    movdqa {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrlq $48, %xmm0
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movd %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Folded Spill
; CHECK-NEXT:    callq __fixsfti@PLT
; CHECK-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %r12, %rax
; CHECK-NEXT:    cmovbq %rbp, %rdx
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %r15, %rdx
; CHECK-NEXT:    cmovaq %r14, %rax
; CHECK-NEXT:    movq $-1, %r14
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpq %r12, %rax
; CHECK-NEXT:    movq %rax, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; CHECK-NEXT:    cmovpq %r12, %rdx
; CHECK-NEXT:    movq %rdx, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    movhlps {{.*#+}} xmm0 = xmm0[1,1]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; CHECK-NEXT:    callq __fixsfti@PLT
; CHECK-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %r12, %rax
; CHECK-NEXT:    cmovbq %rbp, %rdx
; CHECK-NEXT:    movq %rbp, %r13
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %r15, %rdx
; CHECK-NEXT:    cmovaq %r14, %rax
; CHECK-NEXT:    movq $-1, %r14
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpq %r12, %rax
; CHECK-NEXT:    movq %rax, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; CHECK-NEXT:    cmovpq %r12, %rdx
; CHECK-NEXT:    movq %rdx, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; CHECK-NEXT:    movdqa {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrldq {{.*#+}} xmm0 = xmm0[10,11,12,13,14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movd %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Folded Spill
; CHECK-NEXT:    callq __fixsfti@PLT
; CHECK-NEXT:    movq %rdx, %rbp
; CHECK-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %r12, %rax
; CHECK-NEXT:    cmovbq %r13, %rbp
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %r15, %rbp
; CHECK-NEXT:    movq %r15, %r13
; CHECK-NEXT:    cmovaq %r14, %rax
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpq %r12, %rax
; CHECK-NEXT:    movq %rax, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; CHECK-NEXT:    cmovpq %r12, %rbp
; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[3,3,3,3]
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; CHECK-NEXT:    callq __fixsfti@PLT
; CHECK-NEXT:    movq %rax, %r14
; CHECK-NEXT:    movq %rdx, %r15
; CHECK-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovbq %r12, %r14
; CHECK-NEXT:    movabsq $-9223372036854775808, %rax # imm = 0x8000000000000000
; CHECK-NEXT:    cmovbq %rax, %r15
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    cmovaq %r13, %r15
; CHECK-NEXT:    movq $-1, %rax
; CHECK-NEXT:    cmovaq %rax, %r14
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpq %r12, %r14
; CHECK-NEXT:    cmovpq %r12, %r15
; CHECK-NEXT:    movdqa {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    psrldq {{.*#+}} xmm0 = xmm0[14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movd %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Folded Spill
; CHECK-NEXT:    callq __fixsfti@PLT
; CHECK-NEXT:    movq %rax, %r12
; CHECK-NEXT:    movq %rdx, %r13
; CHECK-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    movl $0, %eax
; CHECK-NEXT:    cmovbq %rax, %r12
; CHECK-NEXT:    movabsq $-9223372036854775808, %rcx # imm = 0x8000000000000000
; CHECK-NEXT:    cmovbq %rcx, %r13
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    movabsq $9223372036854775807, %rcx # imm = 0x7FFFFFFFFFFFFFFF
; CHECK-NEXT:    cmovaq %rcx, %r13
; CHECK-NEXT:    movq $-1, %rcx
; CHECK-NEXT:    cmovaq %rcx, %r12
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpq %rax, %r12
; CHECK-NEXT:    cmovpq %rax, %r13
; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    callq __extendhfsf2@PLT
; CHECK-NEXT:    movss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; CHECK-NEXT:    callq __fixsfti@PLT
; CHECK-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    movabsq $-9223372036854775808, %rcx # imm = 0x8000000000000000
; CHECK-NEXT:    cmovbq %rcx, %rdx
; CHECK-NEXT:    movl $0, %esi
; CHECK-NEXT:    cmovbq %rsi, %rax
; CHECK-NEXT:    ucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; CHECK-NEXT:    movabsq $9223372036854775807, %rcx # imm = 0x7FFFFFFFFFFFFFFF
; CHECK-NEXT:    cmovaq %rcx, %rdx
; CHECK-NEXT:    movq $-1, %rcx
; CHECK-NEXT:    cmovaq %rcx, %rax
; CHECK-NEXT:    ucomiss %xmm0, %xmm0
; CHECK-NEXT:    cmovpq %rsi, %rax
; CHECK-NEXT:    movl $0, %ecx
; CHECK-NEXT:    cmovpq %rcx, %rdx
; CHECK-NEXT:    movq %rdx, 8(%rbx)
; CHECK-NEXT:    movq %rax, (%rbx)
; CHECK-NEXT:    movq %r13, 120(%rbx)
; CHECK-NEXT:    movq %r12, 112(%rbx)
; CHECK-NEXT:    movq %r15, 104(%rbx)
; CHECK-NEXT:    movq %r14, 96(%rbx)
; CHECK-NEXT:    movq %rbp, 88(%rbx)
; CHECK-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; CHECK-NEXT:    movq %rax, 80(%rbx)
; CHECK-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; CHECK-NEXT:    movq %rax, 72(%rbx)
; CHECK-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; CHECK-NEXT:    movq %rax, 64(%rbx)
; CHECK-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; CHECK-NEXT:    movq %rax, 56(%rbx)
; CHECK-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; CHECK-NEXT:    movq %rax, 48(%rbx)
; CHECK-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; CHECK-NEXT:    movq %rax, 40(%rbx)
; CHECK-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; CHECK-NEXT:    movq %rax, 32(%rbx)
; CHECK-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; CHECK-NEXT:    movq %rax, 24(%rbx)
; CHECK-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; CHECK-NEXT:    movq %rax, 16(%rbx)
; CHECK-NEXT:    movq %rbx, %rax
; CHECK-NEXT:    addq $104, %rsp
; CHECK-NEXT:    popq %rbx
; CHECK-NEXT:    popq %r12
; CHECK-NEXT:    popq %r13
; CHECK-NEXT:    popq %r14
; CHECK-NEXT:    popq %r15
; CHECK-NEXT:    popq %rbp
; CHECK-NEXT:    retq
;
; AVX512-LABEL: test_signed_v8i128_v8f16:
; AVX512:       # %bb.0:
; AVX512-NEXT:    pushq %rbp
; AVX512-NEXT:    pushq %r15
; AVX512-NEXT:    pushq %r14
; AVX512-NEXT:    pushq %r13
; AVX512-NEXT:    pushq %r12
; AVX512-NEXT:    pushq %rbx
; AVX512-NEXT:    subq $104, %rsp
; AVX512-NEXT:    vmovdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; AVX512-NEXT:    movq %rdi, %rbx
; AVX512-NEXT:    vpsrld $16, %xmm0, %xmm1
; AVX512-NEXT:    vcvtsh2ss %xmm1, %xmm1, %xmm0
; AVX512-NEXT:    vmovss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; AVX512-NEXT:    callq __fixsfti@PLT
; AVX512-NEXT:    xorl %r12d, %r12d
; AVX512-NEXT:    vmovss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; AVX512-NEXT:    # xmm0 = mem[0],zero,zero,zero
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovbq %r12, %rax
; AVX512-NEXT:    movabsq $-9223372036854775808, %rcx # imm = 0x8000000000000000
; AVX512-NEXT:    cmovbq %rcx, %rdx
; AVX512-NEXT:    movq %rcx, %r14
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    movabsq $9223372036854775807, %rcx # imm = 0x7FFFFFFFFFFFFFFF
; AVX512-NEXT:    cmovaq %rcx, %rdx
; AVX512-NEXT:    movq %rcx, %r15
; AVX512-NEXT:    movq $-1, %rcx
; AVX512-NEXT:    cmovaq %rcx, %rax
; AVX512-NEXT:    movq $-1, %r13
; AVX512-NEXT:    vucomiss %xmm0, %xmm0
; AVX512-NEXT:    cmovpq %r12, %rax
; AVX512-NEXT:    movq %rax, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; AVX512-NEXT:    cmovpq %r12, %rdx
; AVX512-NEXT:    movq %rdx, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; AVX512-NEXT:    vmovshdup {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; AVX512-NEXT:    # xmm0 = mem[1,1,3,3]
; AVX512-NEXT:    vcvtsh2ss %xmm0, %xmm0, %xmm0
; AVX512-NEXT:    vmovss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; AVX512-NEXT:    callq __fixsfti@PLT
; AVX512-NEXT:    vmovss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; AVX512-NEXT:    # xmm0 = mem[0],zero,zero,zero
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovbq %r12, %rax
; AVX512-NEXT:    cmovbq %r14, %rdx
; AVX512-NEXT:    movq %r14, %rbp
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovaq %r15, %rdx
; AVX512-NEXT:    cmovaq %r13, %rax
; AVX512-NEXT:    movq $-1, %r14
; AVX512-NEXT:    vucomiss %xmm0, %xmm0
; AVX512-NEXT:    cmovpq %r12, %rax
; AVX512-NEXT:    movq %rax, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; AVX512-NEXT:    cmovpq %r12, %rdx
; AVX512-NEXT:    movq %rdx, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; AVX512-NEXT:    vpsrlq $48, {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; AVX512-NEXT:    vcvtsh2ss %xmm0, %xmm0, %xmm0
; AVX512-NEXT:    vmovss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; AVX512-NEXT:    callq __fixsfti@PLT
; AVX512-NEXT:    vmovss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; AVX512-NEXT:    # xmm0 = mem[0],zero,zero,zero
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovbq %r12, %rax
; AVX512-NEXT:    cmovbq %rbp, %rdx
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovaq %r15, %rdx
; AVX512-NEXT:    cmovaq %r14, %rax
; AVX512-NEXT:    movq $-1, %r14
; AVX512-NEXT:    vucomiss %xmm0, %xmm0
; AVX512-NEXT:    cmovpq %r12, %rax
; AVX512-NEXT:    movq %rax, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; AVX512-NEXT:    cmovpq %r12, %rdx
; AVX512-NEXT:    movq %rdx, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; AVX512-NEXT:    vpermilpd $1, {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; AVX512-NEXT:    # xmm0 = mem[1,0]
; AVX512-NEXT:    vcvtsh2ss %xmm0, %xmm0, %xmm0
; AVX512-NEXT:    vmovss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; AVX512-NEXT:    callq __fixsfti@PLT
; AVX512-NEXT:    vmovss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; AVX512-NEXT:    # xmm0 = mem[0],zero,zero,zero
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovbq %r12, %rax
; AVX512-NEXT:    cmovbq %rbp, %rdx
; AVX512-NEXT:    movq %rbp, %r13
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovaq %r15, %rdx
; AVX512-NEXT:    cmovaq %r14, %rax
; AVX512-NEXT:    movq $-1, %r14
; AVX512-NEXT:    vucomiss %xmm0, %xmm0
; AVX512-NEXT:    cmovpq %r12, %rax
; AVX512-NEXT:    movq %rax, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; AVX512-NEXT:    cmovpq %r12, %rdx
; AVX512-NEXT:    movq %rdx, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; AVX512-NEXT:    vpsrldq $10, {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; AVX512-NEXT:    # xmm0 = mem[10,11,12,13,14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; AVX512-NEXT:    vcvtsh2ss %xmm0, %xmm0, %xmm0
; AVX512-NEXT:    vmovss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; AVX512-NEXT:    callq __fixsfti@PLT
; AVX512-NEXT:    movq %rdx, %rbp
; AVX512-NEXT:    vmovss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; AVX512-NEXT:    # xmm0 = mem[0],zero,zero,zero
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovbq %r12, %rax
; AVX512-NEXT:    cmovbq %r13, %rbp
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovaq %r15, %rbp
; AVX512-NEXT:    movq %r15, %r13
; AVX512-NEXT:    cmovaq %r14, %rax
; AVX512-NEXT:    vucomiss %xmm0, %xmm0
; AVX512-NEXT:    cmovpq %r12, %rax
; AVX512-NEXT:    movq %rax, {{[-0-9]+}}(%r{{[sb]}}p) # 8-byte Spill
; AVX512-NEXT:    cmovpq %r12, %rbp
; AVX512-NEXT:    vpermilps $255, {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; AVX512-NEXT:    # xmm0 = mem[3,3,3,3]
; AVX512-NEXT:    vcvtsh2ss %xmm0, %xmm0, %xmm0
; AVX512-NEXT:    vmovss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; AVX512-NEXT:    callq __fixsfti@PLT
; AVX512-NEXT:    movq %rax, %r14
; AVX512-NEXT:    movq %rdx, %r15
; AVX512-NEXT:    vmovss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; AVX512-NEXT:    # xmm0 = mem[0],zero,zero,zero
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovbq %r12, %r14
; AVX512-NEXT:    movabsq $-9223372036854775808, %rax # imm = 0x8000000000000000
; AVX512-NEXT:    cmovbq %rax, %r15
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    cmovaq %r13, %r15
; AVX512-NEXT:    movq $-1, %rax
; AVX512-NEXT:    cmovaq %rax, %r14
; AVX512-NEXT:    vucomiss %xmm0, %xmm0
; AVX512-NEXT:    cmovpq %r12, %r14
; AVX512-NEXT:    cmovpq %r12, %r15
; AVX512-NEXT:    vpsrldq $14, {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
; AVX512-NEXT:    # xmm0 = mem[14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; AVX512-NEXT:    vcvtsh2ss %xmm0, %xmm0, %xmm0
; AVX512-NEXT:    vmovss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; AVX512-NEXT:    callq __fixsfti@PLT
; AVX512-NEXT:    movq %rax, %r12
; AVX512-NEXT:    movq %rdx, %r13
; AVX512-NEXT:    vmovss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; AVX512-NEXT:    # xmm0 = mem[0],zero,zero,zero
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    movl $0, %eax
; AVX512-NEXT:    cmovbq %rax, %r12
; AVX512-NEXT:    movabsq $-9223372036854775808, %rcx # imm = 0x8000000000000000
; AVX512-NEXT:    cmovbq %rcx, %r13
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    movabsq $9223372036854775807, %rcx # imm = 0x7FFFFFFFFFFFFFFF
; AVX512-NEXT:    cmovaq %rcx, %r13
; AVX512-NEXT:    movq $-1, %rcx
; AVX512-NEXT:    cmovaq %rcx, %r12
; AVX512-NEXT:    vucomiss %xmm0, %xmm0
; AVX512-NEXT:    cmovpq %rax, %r12
; AVX512-NEXT:    cmovpq %rax, %r13
; AVX512-NEXT:    vmovaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; AVX512-NEXT:    vcvtsh2ss %xmm0, %xmm0, %xmm0
; AVX512-NEXT:    vmovss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
; AVX512-NEXT:    callq __fixsfti@PLT
; AVX512-NEXT:    vmovss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
; AVX512-NEXT:    # xmm0 = mem[0],zero,zero,zero
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    movabsq $-9223372036854775808, %rcx # imm = 0x8000000000000000
; AVX512-NEXT:    cmovbq %rcx, %rdx
; AVX512-NEXT:    movl $0, %esi
; AVX512-NEXT:    cmovbq %rsi, %rax
; AVX512-NEXT:    vucomiss {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    movabsq $9223372036854775807, %rcx # imm = 0x7FFFFFFFFFFFFFFF
; AVX512-NEXT:    cmovaq %rcx, %rdx
; AVX512-NEXT:    movq $-1, %rcx
; AVX512-NEXT:    cmovaq %rcx, %rax
; AVX512-NEXT:    vucomiss %xmm0, %xmm0
; AVX512-NEXT:    cmovpq %rsi, %rax
; AVX512-NEXT:    movl $0, %ecx
; AVX512-NEXT:    cmovpq %rcx, %rdx
; AVX512-NEXT:    movq %rdx, 8(%rbx)
; AVX512-NEXT:    movq %rax, (%rbx)
; AVX512-NEXT:    movq %r13, 120(%rbx)
; AVX512-NEXT:    movq %r12, 112(%rbx)
; AVX512-NEXT:    movq %r15, 104(%rbx)
; AVX512-NEXT:    movq %r14, 96(%rbx)
; AVX512-NEXT:    movq %rbp, 88(%rbx)
; AVX512-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; AVX512-NEXT:    movq %rax, 80(%rbx)
; AVX512-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; AVX512-NEXT:    movq %rax, 72(%rbx)
; AVX512-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; AVX512-NEXT:    movq %rax, 64(%rbx)
; AVX512-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; AVX512-NEXT:    movq %rax, 56(%rbx)
; AVX512-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; AVX512-NEXT:    movq %rax, 48(%rbx)
; AVX512-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; AVX512-NEXT:    movq %rax, 40(%rbx)
; AVX512-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; AVX512-NEXT:    movq %rax, 32(%rbx)
; AVX512-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; AVX512-NEXT:    movq %rax, 24(%rbx)
; AVX512-NEXT:    movq {{[-0-9]+}}(%r{{[sb]}}p), %rax # 8-byte Reload
; AVX512-NEXT:    movq %rax, 16(%rbx)
; AVX512-NEXT:    movq %rbx, %rax
; AVX512-NEXT:    addq $104, %rsp
; AVX512-NEXT:    popq %rbx
; AVX512-NEXT:    popq %r12
; AVX512-NEXT:    popq %r13
; AVX512-NEXT:    popq %r14
; AVX512-NEXT:    popq %r15
; AVX512-NEXT:    popq %rbp
; AVX512-NEXT:    retq
  %x = call <8 x i128> @llvm.fptosi.sat.v8i128.v8f16(<8 x half> %f)
  ret <8 x i128> %x
}
