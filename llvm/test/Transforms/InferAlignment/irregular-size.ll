; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 2
; RUN: opt < %s -passes=infer-alignment -S | FileCheck %s

define void @non_pow2_size(i177 %X) {
; CHECK-LABEL: define void @non_pow2_size
; CHECK-SAME: (i177 [[X:%.*]]) {
; CHECK-NEXT:    [[A:%.*]] = alloca i177, align 8
; CHECK-NEXT:    [[L1:%.*]] = load i177, ptr [[A]], align 8
; CHECK-NEXT:    store i177 [[X]], ptr [[A]], align 8
; CHECK-NEXT:    ret void
;
  %A = alloca i177, align 1
  %L1 = load i177, ptr %A, align 1
  store i177 %X, ptr %A, align 1
  ret void
}

; TODO: For non-byte-sized vectors, current implementation assumes there is
; padding to the next byte boundary between elements.
@vector_i4 = constant [8 x <2 x i4>] zeroinitializer, align 8

define void @load_vector_i4(i4 %X) {
; CHECK-LABEL: define void @load_vector_i4
; CHECK-SAME: (i4 [[X:%.*]]) {
; CHECK-NEXT:    [[PTR0:%.*]] = getelementptr [8 x i8], ptr @vector_i4, i64 7, i64 1
; CHECK-NEXT:    [[RES0:%.*]] = load i4, ptr [[PTR0]], align 1
; CHECK-NEXT:    store i4 [[X]], ptr [[PTR0]], align 1
; CHECK-NEXT:    ret void
;
  %ptr0 = getelementptr [8 x i8], ptr @vector_i4, i64 7, i64 1
  %res0 = load i4, ptr %ptr0, align 1
  store i4 %X, ptr %ptr0, align 1
  ret void
}
