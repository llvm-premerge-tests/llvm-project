; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 2
; RUN: opt < %s -passes=infer-alignment -S | FileCheck %s

; InferAlignment should be able to prove vector alignment in the
; presence of a few mild address computation tricks.

; ------------------------------------------------------------------------------
; load instructions
; ------------------------------------------------------------------------------

@x = external global <2 x i64>, align 16

define <2 x i64> @load_test1() {
; CHECK-LABEL: define <2 x i64> @load_test1() {
; CHECK-NEXT:    [[TMP1:%.*]] = load <2 x i64>, ptr @x, align 16
; CHECK-NEXT:    ret <2 x i64> [[TMP1]]
;
  %tmp1 = load <2 x i64>, ptr @x, align 1
  ret <2 x i64> %tmp1
}

define <2 x i64> @load_test2() {
; CHECK-LABEL: define <2 x i64> @load_test2() {
; CHECK-NEXT:    [[T:%.*]] = alloca <2 x i64>, align 16
; CHECK-NEXT:    call void @use(ptr [[T]])
; CHECK-NEXT:    [[TMP1:%.*]] = load <2 x i64>, ptr [[T]], align 16
; CHECK-NEXT:    ret <2 x i64> [[TMP1]]
;
  %t = alloca <2 x i64>
  call void @use(ptr %t)
  %tmp1 = load <2 x i64>, ptr %t, align 1
  ret <2 x i64> %tmp1
}

; When we see a unaligned load from an insufficiently aligned global or
; alloca, increase the alignment of the load, turning it into an aligned load.

@GLOBAL = internal global [4 x i32] zeroinitializer

define <16 x i8> @load_test3(<2 x i64> %x) {
; CHECK-LABEL: define <16 x i8> @load_test3
; CHECK-SAME: (<2 x i64> [[X:%.*]]) {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP:%.*]] = load <16 x i8>, ptr @GLOBAL, align 16
; CHECK-NEXT:    ret <16 x i8> [[TMP]]
;
entry:
  %tmp = load <16 x i8>, ptr @GLOBAL, align 1
  ret <16 x i8> %tmp
}

@GLOBAL_as1 = internal addrspace(1) global [4 x i32] zeroinitializer

define <16 x i8> @load_test3_as1(<2 x i64> %x) {
; CHECK-LABEL: define <16 x i8> @load_test3_as1
; CHECK-SAME: (<2 x i64> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP:%.*]] = load <16 x i8>, ptr addrspace(1) @GLOBAL_as1, align 16
; CHECK-NEXT:    ret <16 x i8> [[TMP]]
;
  %tmp = load <16 x i8>, ptr addrspace(1) @GLOBAL_as1, align 1
  ret <16 x i8> %tmp
}

@GLOBAL_as1_gep = internal addrspace(1) global [8 x i32] zeroinitializer

define <16 x i8> @load_test3_as1_gep(<2 x i64> %x) {
; CHECK-LABEL: define <16 x i8> @load_test3_as1_gep
; CHECK-SAME: (<2 x i64> [[X:%.*]]) {
; CHECK-NEXT:    [[TMP:%.*]] = load <16 x i8>, ptr addrspace(1) getelementptr inbounds ([8 x i32], ptr addrspace(1) @GLOBAL_as1_gep, i16 0, i16 4), align 16
; CHECK-NEXT:    ret <16 x i8> [[TMP]]
;
  %tmp = load <16 x i8>, ptr addrspace(1) getelementptr ([8 x i32], ptr addrspace(1) @GLOBAL_as1_gep, i16 0, i16 4), align 1
  ret <16 x i8> %tmp
}

; ------------------------------------------------------------------------------
; store instructions
; ------------------------------------------------------------------------------

define void @store_test1(<2 x i64> %y) {
; CHECK-LABEL: define void @store_test1
; CHECK-SAME: (<2 x i64> [[Y:%.*]]) {
; CHECK-NEXT:    store <2 x i64> [[Y]], ptr @x, align 16
; CHECK-NEXT:    ret void
;
  store <2 x i64> %y, ptr @x, align 1
  ret void
}

define void @store_test2(<2 x i64> %y) {
; CHECK-LABEL: define void @store_test2
; CHECK-SAME: (<2 x i64> [[Y:%.*]]) {
; CHECK-NEXT:    [[T:%.*]] = alloca <2 x i64>, align 16
; CHECK-NEXT:    call void @use(ptr [[T]])
; CHECK-NEXT:    store <2 x i64> [[Y]], ptr [[T]], align 16
; CHECK-NEXT:    ret void
;
  %t = alloca <2 x i64>
  call void @use(ptr %t)
  store <2 x i64> %y, ptr %t, align 1
  ret void
}

declare void @use(ptr %t)
