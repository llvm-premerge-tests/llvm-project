; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 2
; RUN: opt < %s -passes=infer-alignment -S | FileCheck %s

; InferAlignment should be able to prove vector alignment in the
; presence of a few mild address computation tricks.

; ------------------------------------------------------------------------------
; alloca
; ------------------------------------------------------------------------------

define void @load_alloca() {
; CHECK-LABEL: define void @load_alloca() {
; CHECK-NEXT:    [[ALLOCA:%.*]] = alloca <2 x i64>, align 16
; CHECK-NEXT:    [[LOAD:%.*]] = load <2 x i64>, ptr [[ALLOCA]], align 16
; CHECK-NEXT:    ret void
;
  %alloca = alloca <2 x i64>
  %load = load <2 x i64>, ptr %alloca, align 1
  ret void
}

define void @store_alloca(<2 x i64> %y) {
; CHECK-LABEL: define void @store_alloca
; CHECK-SAME: (<2 x i64> [[Y:%.*]]) {
; CHECK-NEXT:    [[ALLOCA:%.*]] = alloca <2 x i64>, align 16
; CHECK-NEXT:    store <2 x i64> [[Y]], ptr [[ALLOCA]], align 16
; CHECK-NEXT:    ret void
;
  %alloca = alloca <2 x i64>
  store <2 x i64> %y, ptr %alloca, align 1
  ret void
}

; ------------------------------------------------------------------------------
; global
; ------------------------------------------------------------------------------

@x.vector = external global <2 x i64>, align 16

define void @load_global() {
; CHECK-LABEL: define void @load_global() {
; CHECK-NEXT:    [[LOAD:%.*]] = load <2 x i64>, ptr @x.vector, align 16
; CHECK-NEXT:    ret void
;
  %load = load <2 x i64>, ptr @x.vector, align 1
  ret void
}

define void @store_global(<2 x i64> %y) {
; CHECK-LABEL: define void @store_global
; CHECK-SAME: (<2 x i64> [[Y:%.*]]) {
; CHECK-NEXT:    store <2 x i64> [[Y]], ptr @x.vector, align 16
; CHECK-NEXT:    ret void
;
  store <2 x i64> %y, ptr @x.vector, align 1
  ret void
}

; ------------------------------------------------------------------------------
; array
; ------------------------------------------------------------------------------

; When we see a unaligned load or store from an insufficiently aligned global or
; alloca, increase the alignment, turning it into an aligned load or store.
@x.array = internal global [4 x i32] zeroinitializer

define void @load_global_array() {
; CHECK-LABEL: define void @load_global_array() {
; CHECK-NEXT:    [[LOAD_0:%.*]] = load <16 x i8>, ptr @x.array, align 16
; CHECK-NEXT:    [[GEP:%.*]] = getelementptr [4 x i32], ptr @x.array, i16 0, i16 2
; CHECK-NEXT:    [[LOAD_1:%.*]] = load <16 x i8>, ptr [[GEP]], align 8
; CHECK-NEXT:    ret void
;
  %load.0 = load <16 x i8>, ptr @x.array, align 1

  %gep = getelementptr [4 x i32], ptr @x.array, i16 0, i16 2
  %load.1 = load <16 x i8>, ptr %gep, align 1
  ret void
}

define void @store_global_array() {
; CHECK-LABEL: define void @store_global_array() {
; CHECK-NEXT:    store <16 x i8> zeroinitializer, ptr @x.array, align 16
; CHECK-NEXT:    [[GEP:%.*]] = getelementptr [4 x i32], ptr @x.array, i16 0, i16 2
; CHECK-NEXT:    store <16 x i8> zeroinitializer, ptr [[GEP]], align 8
; CHECK-NEXT:    ret void
;
  store <16 x i8> zeroinitializer, ptr @x.array, align 1

  %gep = getelementptr [4 x i32], ptr @x.array, i16 0, i16 2
  store <16 x i8> zeroinitializer, ptr %gep, align 1
  ret void
}
