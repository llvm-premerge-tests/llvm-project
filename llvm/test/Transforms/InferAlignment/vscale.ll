; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 2
; RUN: opt -passes=no-op-function -S < %s | FileCheck %s

; These tests serve to verify code changes when underlying gep ptr is alloca.
define i32 @gep_alloca_vscale_zero() {
; CHECK-LABEL: define i32 @gep_alloca_vscale_zero() {
; CHECK-NEXT:    [[A:%.*]] = alloca <vscale x 4 x i32>, align 16
; CHECK-NEXT:    [[TMP:%.*]] = getelementptr <vscale x 4 x i32>, ptr [[A]], i32 0, i32 2
; CHECK-NEXT:    [[LOAD:%.*]] = load i32, ptr [[TMP]], align 4
; CHECK-NEXT:    ret i32 [[LOAD]]
;
  %a = alloca <vscale x 4 x i32>
  %tmp = getelementptr <vscale x 4 x i32>, ptr %a, i32 0, i32 2
  %load = load i32, ptr %tmp
  ret i32 %load
}

define void @scalable4i32_to_fixed16i32(ptr %out) {
; CHECK-LABEL: define void @scalable4i32_to_fixed16i32
; CHECK-SAME: (ptr [[OUT:%.*]]) {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP:%.*]] = alloca <vscale x 4 x i32>, align 16
; CHECK-NEXT:    store <16 x i32> zeroinitializer, ptr [[TMP]], align 16
; CHECK-NEXT:    [[RELOAD:%.*]] = load volatile <16 x i32>, ptr [[TMP]], align 16
; CHECK-NEXT:    store <16 x i32> [[RELOAD]], ptr [[OUT]], align 16
; CHECK-NEXT:    ret void
;
entry:
  %tmp = alloca <vscale x 4 x i32>, align 16
  store <16 x i32> zeroinitializer, ptr %tmp, align 16
  %reload = load volatile <16 x i32>, ptr %tmp, align 16
  store <16 x i32> %reload, ptr %out, align 16
  ret void
}

define void @scalable16i32_to_fixed16i32(ptr %out) {
; CHECK-LABEL: define void @scalable16i32_to_fixed16i32
; CHECK-SAME: (ptr [[OUT:%.*]]) {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP:%.*]] = alloca <vscale x 16 x i32>, align 16
; CHECK-NEXT:    store volatile <16 x i32> zeroinitializer, ptr [[TMP]], align 16
; CHECK-NEXT:    [[RELOAD:%.*]] = load volatile <16 x i32>, ptr [[TMP]], align 16
; CHECK-NEXT:    store <16 x i32> [[RELOAD]], ptr [[OUT]], align 16
; CHECK-NEXT:    ret void
;
entry:
  %tmp = alloca <vscale x 16 x i32>, align 16
  store volatile <16 x i32> zeroinitializer, ptr %tmp, align 16
  %reload = load volatile <16 x i32>, ptr %tmp, align 16
  store <16 x i32> %reload, ptr %out, align 16
  ret void
}

define void @scalable32i32_to_scalable16i32(ptr %out) {
; CHECK-LABEL: define void @scalable32i32_to_scalable16i32
; CHECK-SAME: (ptr [[OUT:%.*]]) {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP:%.*]] = alloca <vscale x 32 x i32>, align 16
; CHECK-NEXT:    store volatile <vscale x 16 x i32> zeroinitializer, ptr [[TMP]], align 16
; CHECK-NEXT:    [[RELOAD:%.*]] = load volatile <vscale x 16 x i32>, ptr [[TMP]], align 16
; CHECK-NEXT:    store <vscale x 16 x i32> [[RELOAD]], ptr [[OUT]], align 16
; CHECK-NEXT:    ret void
;
entry:
  %tmp = alloca <vscale x 32 x i32>, align 16
  store volatile <vscale x 16 x i32> zeroinitializer, ptr %tmp, align 16
  %reload = load volatile <vscale x 16 x i32>, ptr %tmp, align 16
  store <vscale x 16 x i32> %reload, ptr %out, align 16
  ret void
}

define void @scalable32i16_to_scalable16i32(ptr %out) {
; CHECK-LABEL: define void @scalable32i16_to_scalable16i32
; CHECK-SAME: (ptr [[OUT:%.*]]) {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP:%.*]] = alloca <vscale x 32 x i16>, align 16
; CHECK-NEXT:    store volatile <vscale x 16 x i32> zeroinitializer, ptr [[TMP]], align 16
; CHECK-NEXT:    [[RELOAD:%.*]] = load volatile <vscale x 16 x i32>, ptr [[TMP]], align 16
; CHECK-NEXT:    store <vscale x 16 x i32> [[RELOAD]], ptr [[OUT]], align 16
; CHECK-NEXT:    ret void
;
entry:
  %tmp = alloca <vscale x 32 x i16>, align 16
  store volatile <vscale x 16 x i32> zeroinitializer, ptr %tmp, align 16
  %reload = load volatile <vscale x 16 x i32>, ptr %tmp, align 16
  store <vscale x 16 x i32> %reload, ptr %out, align 16
  ret void
}

define void @scalable32i16_to_scalable16i32_multiuse(ptr %out, ptr %out2) {
; CHECK-LABEL: define void @scalable32i16_to_scalable16i32_multiuse
; CHECK-SAME: (ptr [[OUT:%.*]], ptr [[OUT2:%.*]]) {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP:%.*]] = alloca <vscale x 32 x i16>, align 16
; CHECK-NEXT:    store volatile <vscale x 16 x i32> zeroinitializer, ptr [[TMP]], align 16
; CHECK-NEXT:    [[RELOAD:%.*]] = load volatile <vscale x 16 x i32>, ptr [[TMP]], align 16
; CHECK-NEXT:    store <vscale x 16 x i32> [[RELOAD]], ptr [[OUT]], align 16
; CHECK-NEXT:    [[RELOAD2:%.*]] = load volatile <vscale x 32 x i16>, ptr [[TMP]], align 16
; CHECK-NEXT:    store <vscale x 32 x i16> [[RELOAD2]], ptr [[OUT2]], align 16
; CHECK-NEXT:    ret void
;
entry:
  %tmp = alloca <vscale x 32 x i16>, align 16
  store volatile <vscale x 16 x i32> zeroinitializer, ptr %tmp, align 16
  %reload = load volatile <vscale x 16 x i32>, ptr %tmp, align 16
  store <vscale x 16 x i32> %reload, ptr %out, align 16
  %reload2 = load volatile <vscale x 32 x i16>, ptr %tmp, align 16
  store <vscale x 32 x i16> %reload2, ptr %out2, align 16
  ret void
}
